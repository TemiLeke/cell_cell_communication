{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62042f97-a76e-4b34-805f-3f1ac81e7288",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tadeoye/miniconda3/envs/scRNA_seq_meta_analysis/lib/python3.10/site-packages/scvi/_settings.py:63: UserWarning: Since v1.0.0, scvi-tools no longer uses a random seed by default. Run `scvi.settings.seed = 0` to reproduce results from previous versions.\n",
      "  self.seed = seed\n",
      "/Users/tadeoye/miniconda3/envs/scRNA_seq_meta_analysis/lib/python3.10/site-packages/scvi/_settings.py:70: UserWarning: Setting `dl_pin_memory_gpu_training` is deprecated in v1.0 and will be removed in v1.1. Please pass in `pin_memory` to the data loaders instead.\n",
      "  self.dl_pin_memory_gpu_training = (\n",
      "/Users/tadeoye/miniconda3/envs/scRNA_seq_meta_analysis/lib/python3.10/site-packages/phenograph/cluster.py:13: DeprecationWarning: Please use `spmatrix` from the `scipy.sparse` namespace, the `scipy.sparse.base` namespace is deprecated.\n",
      "  from scipy.sparse.base import spmatrix\n",
      "/Users/tadeoye/miniconda3/envs/scRNA_seq_meta_analysis/lib/python3.10/site-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, \"__version__\") or LooseVersion(\n",
      "/Users/tadeoye/miniconda3/envs/scRNA_seq_meta_analysis/lib/python3.10/site-packages/torch/utils/tensorboard/__init__.py:6: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  ) < LooseVersion(\"1.15\"):\n",
      "/Users/tadeoye/miniconda3/envs/scRNA_seq_meta_analysis/lib/python3.10/site-packages/pytorch_lightning/__init__.py:42: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('pytorch_lightning')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  __import__(\"pkg_resources\").declare_namespace(__name__)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import scvi\n",
    "import rpy2\n",
    "import scib\n",
    "import json\n",
    "import torch\n",
    "import anndata\n",
    "import logging\n",
    "import warnings\n",
    "import scanorama\n",
    "import anndata2ri\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import scrublet as scr\n",
    "import doubletdetection\n",
    "import decoupler as dc\n",
    "from anndata import AnnData\n",
    "from tabnanny import verbose\n",
    "import matplotlib.pyplot as plt\n",
    "from os import PathLike, fspath\n",
    "import rpy2.robjects as robjects\n",
    "from scipy.sparse import csr_matrix\n",
    "from rpy2.robjects import pandas2ri\n",
    "from matplotlib.pyplot import rcParams\n",
    "from rpy2.robjects.packages import importr\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from rpy2.robjects.conversion import localconverter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c36a2bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sys_dpi(width, height, diag):\n",
    "    '''\n",
    "    obtain dpi of system\n",
    "    \n",
    "    w: width in pixels (if unsure, go vist `whatismyscreenresolution.net`)\n",
    "    h: height in pixels\n",
    "    d: diagonal in inches\n",
    "    '''\n",
    "    w_inches = (diag**2/ (1 + height**2/width**2))**0.5\n",
    "    return round(width/w_inches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "447b6d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tadeoye/miniconda3/envs/scRNA_seq_meta_analysis/lib/python3.10/site-packages/rpy2/robjects/pandas2ri.py:368: DeprecationWarning: The global conversion available with activate() is deprecated and will be removed in the next major release. Use a local converter.\n",
      "  warnings.warn('The global conversion available with activate() '\n",
      "/Users/tadeoye/miniconda3/envs/scRNA_seq_meta_analysis/lib/python3.10/site-packages/rpy2/robjects/numpy2ri.py:241: DeprecationWarning: The global conversion available with activate() is deprecated and will be removed in the next major release. Use a local converter.\n",
      "  warnings.warn('The global conversion available with activate() '\n",
      "/Users/tadeoye/miniconda3/envs/scRNA_seq_meta_analysis/lib/python3.10/site-packages/rpy2/robjects/conversion.py:28: DeprecationWarning: The use of converter in module rpy2.robjects.conversion is deprecated. Use rpy2.robjects.conversion.get_conversion() instead of rpy2.robjects.conversion.converter.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "anndata     0.8.0\n",
      "scanpy      1.9.3\n",
      "-----\n",
      "PIL                         9.5.0\n",
      "absl                        NA\n",
      "aiobotocore                 2.5.3\n",
      "aiohttp                     3.8.4\n",
      "aioitertools                0.11.0\n",
      "aiosignal                   1.3.1\n",
      "anndata2ri                  1.1\n",
      "annoy                       NA\n",
      "anyio                       NA\n",
      "appnope                     0.1.3\n",
      "asttokens                   NA\n",
      "async_timeout               4.0.2\n",
      "attr                        23.1.0\n",
      "backcall                    0.2.0\n",
      "botocore                    1.31.17\n",
      "bs4                         4.12.2\n",
      "certifi                     2023.05.07\n",
      "cffi                        1.15.1\n",
      "charset_normalizer          3.1.0\n",
      "chex                        0.1.7\n",
      "click                       8.1.3\n",
      "comm                        0.1.3\n",
      "contextlib2                 NA\n",
      "croniter                    NA\n",
      "cycler                      0.10.0\n",
      "cython_runtime              NA\n",
      "dateutil                    2.8.2\n",
      "debugpy                     1.6.7\n",
      "decorator                   5.1.1\n",
      "decoupler                   1.4.0\n",
      "deepdiff                    6.3.0\n",
      "deprecate                   0.3.2\n",
      "deprecated                  1.2.14\n",
      "docrep                      0.3.2\n",
      "dot_parser                  NA\n",
      "doubletdetection            4.2\n",
      "etils                       1.3.0\n",
      "executing                   1.2.0\n",
      "fastapi                     0.88.0\n",
      "fbpca                       NA\n",
      "flax                        0.6.10\n",
      "frozenlist                  1.3.3\n",
      "fsspec                      2023.6.0\n",
      "google                      NA\n",
      "h5py                        3.9.0\n",
      "idna                        3.4\n",
      "igraph                      0.10.4\n",
      "importlib_resources         NA\n",
      "intervaltree                NA\n",
      "ipykernel                   6.23.2\n",
      "ipywidgets                  8.0.6\n",
      "jax                         0.4.12\n",
      "jaxlib                      0.4.12\n",
      "jedi                        0.18.2\n",
      "jinja2                      3.1.2\n",
      "jmespath                    1.0.1\n",
      "joblib                      1.2.0\n",
      "kiwisolver                  1.4.4\n",
      "leidenalg                   0.9.1\n",
      "lightning                   2.0.3\n",
      "lightning_cloud             NA\n",
      "lightning_utilities         0.8.0\n",
      "llvmlite                    0.39.1\n",
      "louvain                     0.8.0\n",
      "markupsafe                  2.1.3\n",
      "matplotlib                  3.7.1\n",
      "ml_collections              NA\n",
      "ml_dtypes                   0.2.0\n",
      "mpl_toolkits                NA\n",
      "mpmath                      1.3.0\n",
      "msgpack                     1.0.5\n",
      "mudata                      0.2.3\n",
      "multidict                   6.0.4\n",
      "multipart                   0.0.6\n",
      "multipledispatch            0.6.0\n",
      "natsort                     8.4.0\n",
      "numba                       0.56.4\n",
      "numexpr                     2.8.4\n",
      "numpy                       1.23.5\n",
      "numpyro                     0.12.1\n",
      "opt_einsum                  v3.3.0\n",
      "optax                       0.1.5\n",
      "ordered_set                 4.1.0\n",
      "packaging                   23.1\n",
      "pandas                      2.0.2\n",
      "parso                       0.8.3\n",
      "patsy                       0.5.3\n",
      "pexpect                     4.8.0\n",
      "phenograph                  1.5.7\n",
      "pickleshare                 0.7.5\n",
      "pkg_resources               NA\n",
      "platformdirs                3.7.0\n",
      "prompt_toolkit              3.0.38\n",
      "psutil                      5.9.5\n",
      "ptyprocess                  0.7.0\n",
      "pure_eval                   0.2.2\n",
      "pyarrow                     12.0.1\n",
      "pycparser                   2.21\n",
      "pydantic                    1.10.9\n",
      "pydev_ipython               NA\n",
      "pydevconsole                NA\n",
      "pydevd                      2.9.5\n",
      "pydevd_file_utils           NA\n",
      "pydevd_plugins              NA\n",
      "pydevd_tracing              NA\n",
      "pydot                       1.4.2\n",
      "pygments                    2.15.1\n",
      "pyparsing                   3.1.0\n",
      "pyro                        1.8.5\n",
      "pytorch_lightning           1.7.7\n",
      "pytz                        2023.3\n",
      "pytz_deprecation_shim       NA\n",
      "requests                    2.31.0\n",
      "rich                        NA\n",
      "rpy2                        3.5.12\n",
      "s3fs                        2023.6.0\n",
      "scanorama                   1.7.3\n",
      "scib                        1.0.4\n",
      "scipy                       1.10.1\n",
      "scrublet                    NA\n",
      "scvi                        1.0.0\n",
      "seaborn                     0.12.2\n",
      "session_info                1.0.0\n",
      "setuptools                  68.0.0\n",
      "six                         1.16.0\n",
      "sklearn                     1.2.2\n",
      "sniffio                     1.3.0\n",
      "sortedcontainers            2.4.0\n",
      "soupsieve                   2.4.1\n",
      "sparse                      0.14.0\n",
      "stack_data                  0.6.2\n",
      "starlette                   0.22.0\n",
      "statsmodels                 0.14.0\n",
      "sympy                       1.12\n",
      "tensorboard                 2.13.0\n",
      "texttable                   1.6.7\n",
      "threadpoolctl               3.1.0\n",
      "toolz                       0.12.0\n",
      "torch                       2.0.1\n",
      "torchmetrics                0.11.4\n",
      "tornado                     6.3.2\n",
      "tqdm                        4.65.0\n",
      "traitlets                   5.9.0\n",
      "tree                        0.1.8\n",
      "typing_extensions           NA\n",
      "tzlocal                     NA\n",
      "urllib3                     1.26.16\n",
      "uvicorn                     0.22.0\n",
      "wcwidth                     0.2.6\n",
      "websocket                   1.6.0\n",
      "websockets                  11.0.3\n",
      "wrapt                       1.15.0\n",
      "xarray                      2023.5.0\n",
      "yaml                        6.0\n",
      "yarl                        1.9.2\n",
      "zmq                         25.1.0\n",
      "zoneinfo                    NA\n",
      "-----\n",
      "IPython             8.14.0\n",
      "jupyter_client      8.2.0\n",
      "jupyter_core        5.3.1\n",
      "-----\n",
      "Python 3.10.6 (main, Oct 24 2022, 11:04:34) [Clang 12.0.0 ]\n",
      "macOS-10.16-x86_64-i386-64bit\n",
      "-----\n",
      "Session information updated at 2023-10-17 08:16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tadeoye/miniconda3/envs/scRNA_seq_meta_analysis/lib/python3.10/site-packages/session_info/main.py:213: DeprecationWarning: Accessing attr.__version__ is deprecated and will be removed in a future release. Use importlib.metadata directly to query for attrs's packaging metadata.\n",
      "  mod_version = _find_version(mod.__version__)\n"
     ]
    }
   ],
   "source": [
    "# # Ignore R warning messages\n",
    "#Note: this can be commented out to get more verbose R output\n",
    "rpy2.rinterface_lib.callbacks.logger.setLevel(logging.ERROR)\n",
    "\n",
    "# # Automatically convert rpy2 outputs to pandas dataframes\n",
    "# pandas2ri.activate()\n",
    "# anndata2ri.activate()\n",
    "# %load_ext rpy2.ipython\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=PendingDeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Automatically convert rpy2 outputs to pandas dataframes\n",
    "pandas2ri.activate()\n",
    "anndata2ri.activate()\n",
    "%load_ext rpy2.ipython\n",
    "\n",
    "rcParams['figure.dpi'] = get_sys_dpi(1512, 982, 14.125)\n",
    "#rcParams['figure.figsize']=(4,4) #rescale figures\n",
    "\n",
    "sc.settings.verbosity = 3\n",
    "#sc.set_figure_params(dpi=200, dpi_save=300)\n",
    "sc.logging.print_versions()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30cd9808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    WARNING: The R package \"reticulate\" only fixed recently\n",
      "    an issue that caused a segfault when used with rpy2:\n",
      "    https://github.com/rstudio/reticulate/pull/1188\n",
      "    Make sure that you use a version of that package that includes\n",
      "    the fix.\n",
      "    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tadeoye/miniconda3/envs/scRNA_seq_meta_analysis/lib/python3.10/site-packages/rpy2/ipython/rmagic.py:984: DeprecationWarning: The `source` parameter emit a  deprecation warning since IPython 8.0, it had no effects for a long time and will  be removed in future versions.\n",
      "  displaypub.publish_display_data(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "In addition: Warning messages:\n",
       "1: package ‘DESeq2’ was built under R version 4.3.1 \n",
       "2: package ‘S4Vectors’ was built under R version 4.3.1 \n",
       "3: package ‘IRanges’ was built under R version 4.3.1 \n",
       "4: package ‘GenomeInfoDb’ was built under R version 4.3.1 \n",
       "5: package ‘MatrixGenerics’ was built under R version 4.3.1 \n",
       "6: In checkMatrixPackageVersion() :\n",
       "  Package version inconsistency detected.\n",
       "TMB was built with Matrix version 1.6.0\n",
       "Current Matrix version is 1.6.1.1\n",
       "Please re-install 'TMB' from source using install.packages('TMB', type = 'source') or ask CRAN for a binary version of 'TMB' matching CRAN's 'Matrix' package\n",
       "7: In checkDepPackageVersion(dep_pkg = \"TMB\") :\n",
       "  Package version inconsistency detected.\n",
       "glmmTMB was built with TMB version 1.9.3\n",
       "Current TMB version is 1.9.6\n",
       "Please re-install glmmTMB from source or restore original ‘TMB’ package (see '?reinstalling' for more information)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "suppressPackageStartupMessages({\n",
    "    library(reticulate)\n",
    "    library(ggplot2)\n",
    "    library(tidyr)\n",
    "    library(dplyr)\n",
    "    library(purrr)\n",
    "    library(Seurat)\n",
    "    library(tibble)\n",
    "    library(magrittr) \n",
    "    library(forcats)\n",
    "    library(Matrix)\n",
    "    library(stats)\n",
    "    library(tester)\n",
    "    library(Seurat)\n",
    "    library(methods)\n",
    "    library(matrixStats)\n",
    "    library(edgeR)\n",
    "    library(DESeq2)\n",
    "    library(limma)\n",
    "    library(pbmcapply)\n",
    "    library(parallel)\n",
    "    library(lmerTest)\n",
    "    library(lme4)\n",
    "    library(glmmTMB)\n",
    "    library(blme)\n",
    "# needs to be run every time you start R and want to use %>%\n",
    "})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10be21f0-000d-48d7-9e97-4051ec9da0bd",
   "metadata": {},
   "source": [
    "# **1. Reading in the data**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d40204d0-56d5-4984-a2af-1075b64098f1",
   "metadata": {},
   "source": [
    "## **Prepare data**\n",
    "\n",
    "Now, we load the preprocessed and annotated data for downstream analysis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3bc72a63",
   "metadata": {},
   "source": [
    "Please set `get_cell_types=True` if, `cell_type` column is absent or contains celltype annotation not of the form\n",
    "\n",
    "- `Excitatory`, `Inhibitory`, `Astrocyte`, `Oligodendrocyte`, `OPC`, `Microglia`, `Endothelial`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e763f1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_prefix = 'gazestani_pfc'\n",
    "get_cell_types = False\n",
    "\n",
    "adata_annot = sc.read_h5ad(f'../data/raw/{save_prefix}/{save_prefix}_raw_anndata.h5ad')\n",
    "adata_annot.obs_names_make_unique()\n",
    "adata_annot.var_names_make_unique()\n",
    "\n",
    "if 'counts' not in adata_annot.layers.keys():\n",
    "    adata_annot.layers['counts'] = adata_annot.X.copy()\n",
    "else:\n",
    "    adata_annot.X = adata_annot.layers['counts'].copy()\n",
    "\n",
    "layer_keys = list(adata_annot.layers.keys())\n",
    "\n",
    "for layer in layer_keys:\n",
    "    if layer != 'counts':\n",
    "        del adata_annot.layers[layer]\n",
    "\n",
    "adata_annot.X = adata_annot.X.astype(np.float32)\n",
    "adata_annot.layers['counts'] = adata_annot.layers['counts'].astype(np.float32)\n",
    "    \n",
    "del adata_annot.obsm, adata_annot.varm, adata_annot.uns, adata_annot.obsp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bd3dcd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 892828 × 38199\n",
       "    obs: 'nUMI', 'nGene', 'dataset', 'clusters', 'QC_Gene_total_count_x', 'QC_Gene_unique_count_x', 'QC_MT.pct_x', 'QC_IEG.pct_x', 'QC_top50_pct_x', 'status', 'anno_batch_x', 'sample', 'anno_organism', 'ds_batch', 'anno_batch_y', 'anno_orig_cellState', 'anno_age', 'anno_sex', 'anno_First_author', 'anno_pmid', 'anno_region', 'anno_ctype', 'anno_class', 'anno_braak_score', 'anno_condition', 'anno_RNAseq_profiling_method', 'anno_RNAseq_platform', 'QC_MT.pct_y', 'QC_IEG.pct_y', 'QC_Gene_total_count_y', 'QC_Gene_unique_count_y', 'QC_top50_pct_y', 'UMAP_1', 'UMAP_2', 'cell_barcode', 'anno_ctype2', 'QC_lncRNA_pct', 'percent.mito', 'dataset2', 'QC_OXPHOS.pct', 'status2', 'pathology.group', 'cell_type', 'individualID'\n",
       "    layers: 'counts'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_annot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c741d75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "celltypes = [\"OPC\"]\n",
    "#\"Excitatory\", \"Inhibitory\", \"Astrocyte\", \"Microglia\", \"Oligodendrocyte\", \"OPC\", \"Endothelial\"\n",
    "\n",
    "mapping = {'leng_etc':\n",
    "           \n",
    "           {'Exc': 'Excitatory', \n",
    "            'Inh': 'Inhibitory', \n",
    "            'Astro': 'Astrocyte',\n",
    "            'Endo': 'Endothelial', \n",
    "            'Micro': 'Microglia', \n",
    "            'OPC': 'OPC', \n",
    "            'Oligo': 'Oligodendrocyte'},\n",
    "\n",
    "           'leng_sfg':\n",
    "           \n",
    "           {'Exc': 'Excitatory', \n",
    "            'Inh': 'Inhibitory', \n",
    "            'Astro': 'Astrocyte',\n",
    "            'Endo': 'Endothelial', \n",
    "            'Micro': 'Microglia', \n",
    "            'OPC': 'OPC', \n",
    "            'Oligo': 'Oligodendrocyte'},\n",
    "           \n",
    "           'allen_mtg':\n",
    "           \n",
    "           {'Excitatory': 'Excitatory', \n",
    "            'Inhibitory': 'Inhibitory',\n",
    "            'Astrocyte': 'Astrocyte',\n",
    "            'Microglia': 'Microglia', \n",
    "            'Endothelial': 'Endothelial', \n",
    "            'OPC': 'OPC',\n",
    "            'Oligodendrocyte': 'Oligodendrocyte'},\n",
    "            \n",
    "            'seaad_mtg':\n",
    "           \n",
    "           {'Excitatory': 'Excitatory', \n",
    "            'Inhibitory': 'Inhibitory',\n",
    "            'Astrocyte': 'Astrocyte',\n",
    "            'Microglia': 'Microglia', \n",
    "            'Endothelial': 'Endothelial', \n",
    "            'OPC': 'OPC',\n",
    "            'Oligodendrocyte': 'Oligodendrocyte'},\n",
    "\n",
    "            \"gazestani_pfc\":\n",
    "\n",
    "            {'ExN': 'Excitatory', \n",
    "                     'InN': 'Inhibitory',\n",
    "                     'Astro': 'Astrocyte',\n",
    "                     'MG': 'Microglia',\n",
    "                     'OPC': 'OPC',\n",
    "                     'Oligo': 'Oligodendrocyte',\n",
    "                     'Endo': 'Endothelial'},\n",
    "            }\n",
    "\n",
    "cell_column = {'leng_etc': 'clusterCellType',\n",
    "               'leng_sfg': 'clusterCellType',\n",
    "               'allen_mtg': 'cell_labels',\n",
    "               'seaad_mtg': 'cell_type',\n",
    "               'gazestani_pfc': 'cell_type',\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "093d77f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if get_cell_types:\n",
    "    adata_annot.obs['cell_type'] = adata_annot.obs[cell_column[save_prefix]].map(mapping[save_prefix])\n",
    "\n",
    "adata_annot = adata_annot[adata_annot.obs.cell_type.isin(celltypes)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "53847a6f",
   "metadata": {},
   "source": [
    "## **Differential Expression Frameworks**\n",
    "\n",
    "\n",
    "### **Overview:**\n",
    "\n",
    "Based on the findings of **[Gazestani. et. al. 2023](https://www.sciencedirect.com/science/article/pii/S0092867423008590?via%3Dihub)**, this framework employs a pseudocell strategy. This approach combines mixed linear models and jack-knifing techniques to robustly identify differentially expressed genes\n",
    "\n",
    "### **Pseudocell Construction and DEG Identification:**\n",
    "\n",
    "1. **Aggregation:** We first aggregate the raw UMI count of, on average, every 30 cells per subject and cell type. We constructed one pseudocell for cell types that had between 15 to 45 cells in a donor and excluded cell types that had less than 15 cells. This pseudocell-based analysis reduces the impact of dropout and technical variability, while ameliorating low statistical power and high variation in sample size issues attributed to the pseudobulk approaches.\n",
    "\n",
    "2. **Differential Testing:** We then used the `Limma Trend` approach with robust moderated t-statistic to identify DE genes within each cell class with specififc coveraiates such as `sex`, `cell type`, `log2(pseudocell MT%)` and `log2(pseudocell nUMI)` as fixed effects and `subject id` as a random effect. \n",
    "\n",
    "\n",
    "### **Parameters:**\n",
    "\n",
    "- `metadata`: Path to metadata. It must include a `pathology.group` column with unique groups being `no`, `early`, and `late`.\n",
    "\n",
    "- `map_meta`: Indicates if metadata mapping is required for `pathology.group`. If set to False, `pathology.group` must exist in `adata.obs`\n",
    "\n",
    "- `test_names`: List of the different test names of interest.\n",
    "\n",
    "- `save_prefix`: Preferred prefix for saving critical files. Ideally chosen to be in the format `{source name}_{brain region}`. e.g `mathys_pfc`\n",
    "\n",
    "- `subject_id`: Column name for Subject/Patient ID in both metadata and `.obs`\n",
    "\n",
    "- `deg_methods_to_run`: List of methods for the differential expression analysis. Options include: `Trend`, `Voom`, `VoomSampleWeights`, `Dream`. **default: `Trend`**\n",
    "\n",
    "- `covariates`: List of covariates, including (`including pathology.group`, ) e.g `Sex`, `Sample Batch`, and `Age`. Covariates can be factors that are not of primary interest but might have an effect on the pathological status. For no additional confounders, set `covaraites = ['pathology.group']`.\n",
    "\n",
    "    - `Note`: Ensure that continuous covariates are similarly scaled. For instance, %MT should range between 0-100, and nGene/nUMI values should undergo a log2() transformation.\n",
    "\n",
    "    - `Standardization`: Maintain uniformity in categorical data. E.g., Avoid having 'M', 'Male', and 'male' in the same dataset.\n",
    "\n",
    "    - `Impact Assessment`: Regularly assess the impact of the covariates included the DE results by excluding them one by one and checking how the DE patterns change. If a covariate unduly influences results, exercise caution.\n",
    "\n",
    "- `filter_genes`: Setermines if genes should be filtered using `gene_celltype_threshold` before DE tests.\n",
    "\n",
    "- `jack_kniffing`: Logical whether to perform Jack-knifing esampling technique. `This technique is most usefull when we are dealing with large datasets with +10 controls and +10 experiment conditions.` Therefore, the parameter is automatically set to `False if number of subjects is less than or equal to 10`.\n",
    "\n",
    "\n",
    "### **Parameters To Main DE Function:**\n",
    "\n",
    "The primary differential expression analysis function accepts:\n",
    "\n",
    "\n",
    "- `inputExpData`: Input (aggregated) SingleCellExperiment data format.\n",
    "\n",
    "- `covariates`: Column names for covariates, including the main effect. \n",
    "\n",
    "- `randomEffect`: Column name for the random effect (in this case `subject_id`). For pseudobulk data, set as NULL.\n",
    "\n",
    "- `DEmethod`: Method used for the differential expression analysis. Options: `Trend`, `Voom`, `VoomSampleWeights`, `Dream`. **default: `Trend`**\n",
    "\n",
    "- `normalization`: Normalization method. Options: `CPM`, `TMM`, `VST`, `rmTop50`, and `none`. **default: `CPM`**\n",
    "\n",
    "- `quantile.norm`:Specifies quantile normalization on normalized data. **Default is F**. Helpful if highly expressed genes, like `MALAT1`, are being identified as differentially expressed.\n",
    "\n",
    "- `bkg_genes`: Background genes (filtered) used for differntial expression testing. `usually set to genes expressed in >1% of cells`. Can be provided to substantially speed up re-runs (in case exploring effect of different co-variates on DE genes). default: NULL\n",
    "\n",
    "    - `Note`: Scrutinize the count of background genes in the analysis. Overly conservative settings might skip many DE genes, while overly liberal ones could introduce noise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1ba83ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_meta = True\n",
    "filter_genes = \"TRUE\"\n",
    "\n",
    "subject_ids_for_study = {'allen_mtg': 'individualID',\n",
    "                        'leng_sfg': 'PatientID',\n",
    "                        'leng_etc': 'PatientID',\n",
    "                        'seaad_mtg': 'Donor ID', \n",
    "                        'gazestani_pfc': 'individualID'}\n",
    "\n",
    "covaraites_for_study = {'allen_mtg': ['pathology.group', 'QC_Gene_total_log', 'QC_MT.pct'], # ['ageDeath.cat', 'sex_y',],\n",
    "                        'leng_sfg': ['pathology.group', 'QC_Gene_total_log', 'QC_MT.pct'],  # ['ageDeath.cat',],\n",
    "                        'leng_etc': ['pathology.group', 'QC_Gene_total_log', 'QC_MT.pct'],  # ['ageDeath.cat',]\n",
    "                        'seaad_mtg': ['pathology.group', 'QC_Gene_total_log', 'QC_MT.pct'],\n",
    "                        'gazestani_pfc': ['pathology.group', 'Gender', 'APOE', 'QC_Gene_total_log', 'QC_MT.pct']}\n",
    "\n",
    "subject_id = subject_ids_for_study[save_prefix]    # for leng this is `PatientID` for mathys is 'Subject', and allen is 'individualID'\n",
    "gene_celltype_threshold = 0.01                     # determines number of cells the gene must be expressed in \n",
    "covariates = covaraites_for_study[save_prefix]     # list of covariates to be accounted for in regression.\n",
    "\n",
    "test_names = ['early_vs_no', 'late_vs_early', 'late_vs_no', 'ad_vs_no']\n",
    "\n",
    "metadata = f'../data/raw/{save_prefix}/{save_prefix}_metadata.csv' \n",
    "\n",
    "\n",
    "######################### Differential expression arguments #########################\n",
    "\n",
    "pseudobulking_strategies = ['network', 'random', 'bulk'] # options 'network', 'random', 'smaller_network', 'bulk'\n",
    "deg_methods_to_run = [\"Trend\"] # options \"Voom\", \"VoomSampleWeights\", \"Dream\" default: \"Trend\"\n",
    "normalization_methods = [\"CPM\"] # options: \"TMM\", \"VST\", \"rmTop50\", \"none\" default: \"CPM\"\n",
    "randomEffect = subject_id\n",
    "covariates = covaraites_for_study[save_prefix]\n",
    "jack_knifing = False # False if adata_annot.obs[subject_id].nunique()<=10 else True\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a5d8a01b",
   "metadata": {},
   "source": [
    "## **Differential Gene Expression Analysis with Pseudocell approach [Gazestani. et. al. 2023](https://www.sciencedirect.com/science/article/pii/S0092867423008590?via%3Dihub)**\n",
    "\n",
    "Most existing approaches use either a cell-based or pseudobulk-based approach to identify differentially expressed genes. The issue with the cell-based approaches is that they take a long time to run and are sensitive to the drop-out issue in the single cell data. The pseudobulk methods overcome both these limitations by aggregating the expression of cells from the same cell type and individual into one (pseudo) bulk sample. The issue that raises due to this procedure is the loss of statistical power. As illustration, consider the case where we have sampled 10 cells from a cell type in individual A and 10,000 cells from the same cell type in idividual B. In pseudobulk method, both these individuals would have one pseudobulk sample for this cell type. However, the confidence that we have on the gene expression patterns from individual B is much higher than the confidence that we have in gene expression patterns from individual A; and pseudobulk methods are blind to this. It doesn't matter if you sample 10 cells from a cell type or 10k cellsin pseudobulk samples, it simply ignores this while in reallity they are very different on the level of confidence that they provide.\n",
    "\n",
    "To address these challenges we use a pseudocell approach. This method is in between the cell-based and pseudobulk-based approaches, so it can take advantage of each method while remedying the issues attributed to them.\n",
    "The first step for a pseudocell based differential expression analysis is generation of the pseudocells from the single cell expression data. Each pseudocell is usually defined as a combination of 10 to 50 cells. Pseudocells are calucalted by summing the raw UMI count matrices. There are two main functions in scOnline for the construction of pseudocells:\n",
    "\n",
    "\n",
    "- `To generate pseudocells that are composed of, on average, 20 cells or higher. This function can also generate pseudobulk samples.`\n",
    "\n",
    "- `To generate pseudocells that are on average composed of 10 cells`\n",
    "\n",
    "We start with generating pseudocells using function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "edb67647",
   "metadata": {},
   "source": [
    "## **Map Metadata**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3301215",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv(metadata, encoding_errors='ignore')\n",
    "meta = meta.astype(str)\n",
    "mapping = dict(zip(meta[subject_id], meta['pathology.group']))\n",
    "adata_annot.obs['pathology.group'] = adata_annot.obs[subject_id].map(mapping)\n",
    "\n",
    "if \" \" in subject_id:\n",
    "    subject_id2  = \"\".join(subject_id.split(\" \"))\n",
    "    adata_annot.obs[subject_id2] = adata_annot.obs[subject_id].copy()\n",
    "    del adata_annot.obs[subject_id]\n",
    "    subject_id = subject_id2\n",
    "    randomEffect = subject_id\n",
    "\n",
    "for covariate in covariates:\n",
    "    try:\n",
    "        mapping = dict(zip(meta[subject_id], meta[covariate]))\n",
    "        adata_annot.obs[covariate] = adata_annot.obs[subject_id].map(mapping)\n",
    "    except KeyError:\n",
    "        continue\n",
    "\n",
    "for obs in adata_annot.obs.columns:\n",
    "    if obs not in covariates + [subject_id, 'cell_type']:\n",
    "        del adata_annot.obs[obs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2027869a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 34867 × 38199\n",
       "    obs: 'pathology.group', 'cell_type', 'individualID', 'Gender', 'APOE'\n",
       "    layers: 'counts'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_annot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "866e1208",
   "metadata": {},
   "source": [
    "## **Loading data into memory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a679ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tadeoye/miniconda3/envs/scRNA_seq_meta_analysis/lib/python3.10/site-packages/rpy2/robjects/pandas2ri.py:368: DeprecationWarning: The global conversion available with activate() is deprecated and will be removed in the next major release. Use a local converter.\n",
      "  warnings.warn('The global conversion available with activate() '\n",
      "/Users/tadeoye/miniconda3/envs/scRNA_seq_meta_analysis/lib/python3.10/site-packages/rpy2/robjects/numpy2ri.py:241: DeprecationWarning: The global conversion available with activate() is deprecated and will be removed in the next major release. Use a local converter.\n",
      "  warnings.warn('The global conversion available with activate() '\n",
      "/Users/tadeoye/miniconda3/envs/scRNA_seq_meta_analysis/lib/python3.10/site-packages/rpy2/robjects/conversion.py:28: DeprecationWarning: The use of converter in module rpy2.robjects.conversion is deprecated. Use rpy2.robjects.conversion.get_conversion() instead of rpy2.robjects.conversion.converter.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class: SingleCellExperiment \n",
      "dim: 38199 34867 \n",
      "metadata(0):\n",
      "assays(2): X counts\n",
      "rownames(38199): A1BG A1BG-AS1 ... snoZ5 snosnR66\n",
      "rowData names(0):\n",
      "colnames(34867): human_iNPH_1020Y1_TACCGGGGTAGGACCA-1\n",
      "  human_iNPH_1020Y1_ACTATCTCAATCTGCA-1 ...\n",
      "  human_iNPH_1074D_TTTGGAGTCAAATGCC-1\n",
      "  human_iNPH_1074D_TCCTAATCATAGATCC-1\n",
      "colData names(5): pathology.group cell_type individualID Gender APOE\n",
      "reducedDimNames(0):\n",
      "mainExpName: NULL\n",
      "altExpNames(0):\n",
      "[1] \"loaded data into memory for recursive use\"\n"
     ]
    }
   ],
   "source": [
    "%%R -i adata_annot -i celltypes\n",
    "\n",
    "print(adata_annot)\n",
    "\n",
    "print('loaded data into memory for recursive use')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c10e5b17",
   "metadata": {},
   "source": [
    "#### **Pseudoc-cell Differential Expression Analysis with custom scripts adapted from [Gazestani. et. al. 2023](https://www.sciencedirect.com/science/article/pii/S0092867423008590?via%3Dihub)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ca7823",
   "metadata": {},
   "source": [
    "#### **Pseduocell with filtering and QC**\n",
    "\n",
    "\n",
    "The main arguments for running the function:\n",
    "\n",
    "- `parsing.col.names`: a vector of column names to be used to parse the data. Usually the columns related to the donor id and the cell type annotation (see above figure).\n",
    "\n",
    "- `pseudocell.size`: the average size of pseudcoells. If NULL, generates pseudobulk data.\n",
    "\n",
    "- `inputExpData`: Input single cell data object in format.\n",
    "\n",
    "- `min_size_limit`: minimum acceptable size of the pseudocells. usually 10 or 15.\n",
    "\n",
    "- `inputPhenoData`: the meta data on the cells that matches in order with the input PC space to use to create the similarity network. It's highly recommended to be used if. defualt: NULL.\n",
    "\n",
    "- `nPCs`: Number of pcs to use to create the similarity network. Used only if human or mouse\n",
    "\n",
    "- `rand_pseudobulk_mod`: To randomly assign cells to pseudocells in each cell type from each individual; or create a similarity network between these cells and use that similarity net to group cells with highly similar expression patterns to each other. `default: TRUE, but Here we set to FALSE``\n",
    "\n",
    "\n",
    "The authors reiterate that it's highly recommended to provide if the function will generate the embedding for each cell type in each individual. it's possible that such embedding is driven by the quality of the cells in the group opposed to biological variation, and hence quality of the pseudocells and inference on them would be limited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8360a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudocell_size = 30    # the average size of pseudcoells. If NULL, generates pseudobulk data.\n",
    "min_size_limit = 15     # minimum acceptable size of the pseudocells. usually 10 or 15.\n",
    "nPCs = 30               # Number of pcs to use to create the similarity network. Used only if human or mouse\n",
    "organism = 'Human' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d793cbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "del adata_annot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66f7e120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Functions:\n",
      ".myRead10X()\n",
      ".myRead10X_h5()\n",
      ".myLigerToExpSet()\n",
      ".mycBindFn()\n",
      ".myExpSetCreatorFn()\n",
      ".myIntegrative_oneline()\n",
      ".myFindAllMarkers()\n",
      ".myAnnotateFn()\n",
      ".my2dPlot()\n",
      ".myPseudoCellfn_v2()\n",
      ".myLabelTransfer_harmony()\n",
      ".myLabelTransfer_liger()\n",
      ".myMapToHuman()\n",
      ".myRiverPlotFn()\n",
      ".myClusteringOptimizerFn()\n",
      ".myMarkerBasedAnalysisFn()\n",
      ".mycellAssignHeatmap()\n",
      ".myMetaMarkerFn()\n",
      ".myFindNeighbors()\n",
      ".myVlnPlot()\n",
      ".myFeaturePlot()\n",
      ".myheatmap.3()\n",
      ".myEvalMarkers()\n",
      ".myReadGMT()\n",
      ".mySplitObject()\n",
      ".myRTNgsea(two-sided GSEA implementation)\n",
      "[1] \"batch information is in the anno_batch variable\"\n",
      "[1] \"Number of MT genes in the dataset: 30 / 13\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tadeoye/miniconda3/envs/scRNA_seq_meta_analysis/lib/python3.10/site-packages/rpy2/ipython/rmagic.py:984: DeprecationWarning: The `source` parameter emit a  deprecation warning since IPython 8.0, it had no effects for a long time and will  be removed in future versions.\n",
      "  displaypub.publish_display_data(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Loading required package: GenomicFeatures\n",
       "Loading required package: AnnotationDbi\n",
       "\n",
       "Attaching package: ‘AnnotationDbi’\n",
       "\n",
       "The following object is masked from ‘package:dplyr’:\n",
       "\n",
       "    select\n",
       "\n",
       "Loading required package: AnnotationFilter\n",
       "\n",
       "Attaching package: ‘AnnotationFilter’\n",
       "\n",
       "The following object is masked from ‘package:magrittr’:\n",
       "\n",
       "    not\n",
       "\n",
       "\n",
       "Attaching package: 'ensembldb'\n",
       "\n",
       "The following object is masked from 'package:dplyr':\n",
       "\n",
       "    filter\n",
       "\n",
       "The following object is masked from 'package:stats':\n",
       "\n",
       "    filter\n",
       "\n",
       "------------------------------------------------------------------------------\n",
       "You have loaded plyr after dplyr - this is likely to cause problems.\n",
       "If you need functions from both plyr and dplyr, please load plyr first, then dplyr:\n",
       "library(plyr); library(dplyr)\n",
       "------------------------------------------------------------------------------\n",
       "\n",
       "Attaching package: 'plyr'\n",
       "\n",
       "The following object is masked from 'package:IRanges':\n",
       "\n",
       "    desc\n",
       "\n",
       "The following object is masked from 'package:S4Vectors':\n",
       "\n",
       "    rename\n",
       "\n",
       "The following object is masked from 'package:matrixStats':\n",
       "\n",
       "    count\n",
       "\n",
       "The following object is masked from 'package:purrr':\n",
       "\n",
       "    compact\n",
       "\n",
       "The following objects are masked from 'package:dplyr':\n",
       "\n",
       "    arrange, count, desc, failwith, id, mutate, rename, summarise,\n",
       "    summarize\n",
       "\n",
       "\n",
       "Attaching package: 'future'\n",
       "\n",
       "The following object is masked from 'package:AnnotationFilter':\n",
       "\n",
       "    value\n",
       "\n",
       "qs 0.25.5\n",
       "Warning: Feature names cannot have underscores ('_'), replacing with dashes ('-')\n",
       "Performing log-normalization\n",
       "0%   10   20   30   40   50   60   70   80   90   100%\n",
       "[----|----|----|----|----|----|----|----|----|----|\n",
       "**************************************************|\n",
       "Calculating gene variances\n",
       "0%   10   20   30   40   50   60   70   80   90   100%\n",
       "[----|----|----|----|----|----|----|----|----|----|\n",
       "**************************************************|\n",
       "Calculating feature variances of standardized and clipped values\n",
       "0%   10   20   30   40   50   60   70   80   90   100%\n",
       "[----|----|----|----|----|----|----|----|----|----|\n",
       "**************************************************|\n",
       "Centering and scaling data matrix\n",
       "\r  |                                                                            \r  |                                                                      |   0%\r  |                                                                            \r  |===================================                                   |  50%\r  |                                                                            \r  |======================================================================| 100%\n",
       "In addition: Warning messages:\n",
       "1: package ‘scuttle’ was built under R version 4.3.1 \n",
       "2: package ‘ensembldb’ was built under R version 4.3.1 \n",
       "3: package ‘GenomicFeatures’ was built under R version 4.3.1 \n",
       "4: package ‘AnnotationDbi’ was built under R version 4.3.1 \n",
       "5: package 'scran' was built under R version 4.3.1 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R -i covariates -i test_names -i subject_id -i pseudocell_size -i min_size_limit -i nPCs -i organism -i pseudobulking_strategies\n",
    "\n",
    "library(scuttle)\n",
    "library(Matrix)\n",
    "library(ensembldb)\n",
    "library(EnsDb.Hsapiens.v86)\n",
    "\n",
    "source(\"../scripts/functions/deg_functions/sconline_code.R\")\n",
    "\n",
    "#generating the embedding space\n",
    "\n",
    "exp_seurat = .extraExport2SeuratFn(adata_annot) %>%\n",
    "Seurat::NormalizeData() %>%\n",
    "    FindVariableFeatures() %>% \n",
    "    ScaleData() %>% \n",
    "    RunPCA(verbose=F)\n",
    "\n",
    "embedding_data = exp_seurat@reductions$pca@cell.embeddings[,1:30]\n",
    "\n",
    "# generating the pseudocells\n",
    "\n",
    "pseudobulk_strategy <- list()\n",
    "\n",
    "if ('network' %in% pseudobulking_strategies){\n",
    "  #Function adds/modifies three annotation columns: pseuodcell_size, QC_Gene_total_count, QC_Gene_unique_count\n",
    "  #QC_Gene_total_count: equivalant to nUMI for the pseudobulk samples\n",
    "  #QC_Gene_unique_count: equivalant to nGene for the pseudobulk samples\n",
    "  #use scale(tst$QC_Gene_total_count) and scale(tst$pseudocell_size) as additional covariates for the DE analysis\n",
    "\n",
    "  pseudobulk_strategy[['network']] = suppressWarnings(.sconline.PseudobulkGeneration(argList = NULL, \n",
    "                                  # The columns in the pheonData that will be used to parse the expression data \n",
    "                                  # and generate the pseudocell/pseudobulk data\n",
    "                                    parsing.col.names = c(subject_id, 'cell_type'), \n",
    "                                  # average pseudocell size.\n",
    "                                    pseudocell.size = pseudocell_size,\n",
    "                                    inputExpData = adata_annot,\n",
    "                                  # minimum acceptable size (ie, #cells) for each pseudobul\n",
    "                                    min_size_limit = min_size_limit,\n",
    "                                  # in case we want to run the function outside sconline space\n",
    "                                    inputPhenoData = as.data.frame(colData(adata_annot)),\n",
    "                                  # the embedding space to be used for the generation of the pseudobulk.\n",
    "                                  # only needed when pseudocell.size is not null\n",
    "                                    inputEmbedding = embedding_data, \n",
    "                                  # the dimension of the embedding space for the construction of pseudobulk data\n",
    "                                    nPCs = nPCs, \n",
    "                                    ncores = 5,\n",
    "                                    rand_pseudobulk_mod = F,\n",
    "                                  # used to identify and estimate Mitochondrial Genes\n",
    "                                    organism = organism))\n",
    "} else {\n",
    "  pseudobulk_strategy[['network']] <- NULL\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786a7fac",
   "metadata": {},
   "source": [
    "#### **Pseudocells with random cell assignment**\n",
    "\n",
    "\n",
    "Alternatively, we can create pseudocells using a method that randomly assign cells to pseudocells in each cell type from each individual by setting `rand_pseudobulk_mod=TRUE`. Rather than the previous method which creates a similarity network between these cells and uses that similarity network to group cells with highly similar expression patterns to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "986918db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"batch information is in the anno_batch variable\"\n",
      "[1] \"Number of MT genes in the dataset: 30 / 13\"\n"
     ]
    }
   ],
   "source": [
    "%%R \n",
    "\n",
    "library(scuttle)\n",
    "library(Matrix)\n",
    "library(ensembldb)\n",
    "library(EnsDb.Hsapiens.v86)\n",
    "\n",
    "#generating the embedding space\n",
    "\n",
    "if ('random' %in% pseudobulking_strategies){\n",
    "\n",
    "  pseudobulk_strategy[['random']] = suppressWarnings(.sconline.PseudobulkGeneration(argList=NULL, \n",
    "                                  # The columns in the pheonData that will be used to parse the expression data \n",
    "                                  # and generate the pseudocell/pseudobulk data\n",
    "                                    parsing.col.names = c(subject_id, 'cell_type'), \n",
    "                                  # average pseudocell size.\n",
    "                                    pseudocell.size = pseudocell_size,\n",
    "                                    inputExpData = adata_annot,\n",
    "                                  # minimum acceptable size (ie, #cells) for each pseudobul\n",
    "                                    min_size_limit = min_size_limit,\n",
    "                                  # in case we want to run the function outside sconline space\n",
    "                                    inputPhenoData = as.data.frame(colData(adata_annot)),\n",
    "                                    ncores = 5,\n",
    "                                    rand_pseudobulk_mod = T,\n",
    "                                  # used to identify and estimate Mitochondrial Genes\n",
    "                                    organism = organism))\n",
    "} else {\n",
    "  pseudobulk_strategy[['random']] <- list()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4648a8",
   "metadata": {},
   "source": [
    "#### **Pseudocells with smaller size**\n",
    "\n",
    "We can also generate pseudocells using that allows us to have pseudocells of smaller size. The main arguments for this function:\n",
    "\n",
    "- `inputExpData`: Input single cell data object in SingleCellExperiment format\n",
    "- `embeddings`: Input PC space to use to create the similarity network. It can't be set to NULL\n",
    "- `pseudobulk_split_col`: The column name to parse the single cell data.\n",
    "- `min_dataset_size`: Minimum number of acceptable pseudocell size. default: 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fd880ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R \n",
    "\n",
    "library(scuttle)\n",
    "library(Matrix)\n",
    "library(ensembldb)\n",
    "library(EnsDb.Hsapiens.v86)\n",
    "\n",
    "\n",
    "#generating the embedding space\n",
    "\n",
    "# exp_seurat = .extraExport2SeuratFn(adata_annot) %>%\n",
    "# Seurat::NormalizeData() %>%\n",
    "#     FindVariableFeatures() %>% \n",
    "#     ScaleData() %>% \n",
    "#     RunPCA(verbose=F)\n",
    "\n",
    "# embedding_data = exp_seurat@reductions$pca@cell.embeddings[,1:30]\n",
    "\n",
    "adata_annot$lib_anno = paste0(adata_annot[[subject_id]], \"_\", adata_annot$cell_type)\n",
    "\n",
    "if ('smaller network' %in% pseudobulking_strategies){\n",
    "\n",
    "    #creates pseudobulk samples of median size 10\n",
    "    pseudobulk_strategy[['smaller network']] = .sconline.Pseudobulk10(inputExpData=adata_annot,\n",
    "                                        embeddings = embedding_data,\n",
    "                                        pseudobulk_split_col = \"lib_anno\",\n",
    "                                        min_dataset_size = 4,\n",
    "                                        organism = organism)\n",
    "} else {\n",
    "    pseudobulk_strategy[['smaller network']] <- NULL\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac9f558",
   "metadata": {},
   "source": [
    "#### **Using Standard Pseudobulk Approach**\n",
    "\n",
    "To benchmark the results, here we also create pseudobulk data. To create pseudobulk data per donor and cluster, we can use the function agian, but setting `pseudocell.size = NULL`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f47c3cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Number of MT genes in the dataset: 30 / 13\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Warning: Feature names cannot have underscores ('_'), replacing with dashes ('-')\n",
       "Performing log-normalization\n",
       "0%   10   20   30   40   50   60   70   80   90   100%\n",
       "[----|----|----|----|----|----|----|----|----|----|\n",
       "**************************************************|\n",
       "Calculating gene variances\n",
       "0%   10   20   30   40   50   60   70   80   90   100%\n",
       "[----|----|----|----|----|----|----|----|----|----|\n",
       "**************************************************|\n",
       "Calculating feature variances of standardized and clipped values\n",
       "0%   10   20   30   40   50   60   70   80   90   100%\n",
       "[----|----|----|----|----|----|----|----|----|----|\n",
       "**************************************************|\n",
       "Centering and scaling data matrix\n",
       "\r  |                                                                            \r  |                                                                      |   0%\r  |                                                                            \r  |===================================                                   |  50%\r  |                                                                            \r  |======================================================================| 100%\n",
       "Loading required package: caret\n",
       "Loading required package: lattice\n",
       "\n",
       "Attaching package: 'caret'\n",
       "\n",
       "The following object is masked from 'package:future':\n",
       "\n",
       "    cluster\n",
       "\n",
       "The following object is masked from 'package:purrr':\n",
       "\n",
       "    lift\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R \n",
    "\n",
    "library(scuttle)\n",
    "library(Matrix)\n",
    "library(ensembldb)\n",
    "library(EnsDb.Hsapiens.v86)\n",
    "\n",
    "#generating the embedding space\n",
    "\n",
    "exp_seurat = .extraExport2SeuratFn(adata_annot) %>%\n",
    "Seurat::NormalizeData() %>%\n",
    "    FindVariableFeatures() %>% \n",
    "    ScaleData() %>% \n",
    "    RunPCA(verbose=F)\n",
    "\n",
    "embedding_data = exp_seurat@reductions$pca@cell.embeddings[,1:30]\n",
    "\n",
    "if ('bulk' %in% pseudobulking_strategies){\n",
    "\n",
    "  pseudobulk_strategy[['bulk']] = suppressWarnings(.sconline.PseudobulkGeneration(argList = NULL, \n",
    "                                  # The columns in the pheonData that will be used to parse the expression data \n",
    "                                  # and generate the pseudocell/pseudobulk data\n",
    "                                    parsing.col.names = c(subject_id, 'cell_type'), \n",
    "                                  # average pseudocell size.\n",
    "                                    pseudocell.size = NULL,\n",
    "                                    inputExpData = adata_annot,\n",
    "                                  # minimum acceptable size (ie, #cells) for each pseudobul\n",
    "                                    min_size_limit = min_size_limit,\n",
    "                                  # in case we want to run the function outside sconline space\n",
    "                                    inputPhenoData = as.data.frame(colData(adata_annot)),\n",
    "                                  # the embedding space to be used for the generation of the pseudobulk.\n",
    "                                  # only needed when pseudocell.size is not null\n",
    "                                    inputEmbedding = embedding_data, \n",
    "                                  # the dimension of the embedding space for the construction of pseudobulk data\n",
    "                                    nPCs = nPCs, \n",
    "                                    ncores = 3,\n",
    "                                    rand_pseudobulk_mod = F,\n",
    "                                    organism = organism))\n",
    "\n",
    "} else {\n",
    "  pseudobulk_strategy[['bulk']] <- NULL\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16acd4bc",
   "metadata": {},
   "source": [
    "### **DEG Analysis**\n",
    "\n",
    "\n",
    "The main function for differential expression analysis is with following input arguments:\n",
    "\n",
    "- `inputExpData`: Input (aggregated) single cell data object in SingleCellExperiment format\n",
    "\n",
    "- `covariates`: The column names for covariates to be included in the analysis including the main effect\n",
    "\n",
    "    -  This should be a list of covariates (`including pathology.group`, ) e.g `Sex`, `Sample Batch`, `Age` and other factors that might not be of interest but might have an effect on the pathological status. If you would not like to include any additional cofounders, please set `covaraites = ['pathology.group']`.\n",
    "\n",
    "    - `Note 1`: ensure continuous covariates are in similar scales. For example, scale %MT to be in the range of 0-100 and log2() transform nGene/nUMI values.\n",
    "\n",
    "    - `Note 2`: make sure categorical data are standadized in format. e.g., you don't have M, Male, and male in the same dataset. All should be M or male, or Male (it's case sensitive).\n",
    "\n",
    "    - `Note 3`: always assess the impact of the covariates that you are including on the DE results by excluding them one by one and checking how the DE patterns change. You should be cautious if one of them is having out-sized effect on the results\n",
    "\n",
    "- `randomEffect`: The column name for the random effect (it is donor id in most scenarios). Set to NULL for pseudobulk data.\n",
    "\n",
    "- `DEmethod`: Method used for the differential expression analysis. Options: `Trend`, `Voom`, `VoomSampleWeights`, `Dream`. **default: `Trend`**\n",
    "\n",
    "- `normalization`: Normalization method. Options: `CPM`, `TMM`, `VST`, `rmTop50`, and `none`. **default: `CPM`**\n",
    "\n",
    "- `quantile.norm`: Logical, indicating whether or not to do quantile normalization on the normalized data. **default: F.** Specially useful if the highly expressed genes like `MALAT1` are being identified as differentially expressed.\n",
    "\n",
    "- `bkg_genes`: Background genes used for differntial expression testing. usually set to genes expressed in >1% of cells. Can be provided to substantially speed up re-runs (in case exploring effect of different co-variates on DE genes). default: NULL\n",
    "\n",
    "    - `Note 4`: check the number of background genes that are being included in the analysis. If it's too conservative, you would lose many of DE genes (as they are not being tested) and if it's too liberal, noise would be added to the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7317c781",
   "metadata": {},
   "source": [
    "We want to do the DE analysis on each cell-type individually. So first we need to split the pseudocell and pseudobulk samples based on the cluster annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "720cf26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tadeoye/miniconda3/envs/scRNA_seq_meta_analysis/lib/python3.10/site-packages/rpy2/robjects/pandas2ri.py:368: DeprecationWarning: The global conversion available with activate() is deprecated and will be removed in the next major release. Use a local converter.\n",
      "  warnings.warn('The global conversion available with activate() '\n",
      "/Users/tadeoye/miniconda3/envs/scRNA_seq_meta_analysis/lib/python3.10/site-packages/rpy2/robjects/numpy2ri.py:241: DeprecationWarning: The global conversion available with activate() is deprecated and will be removed in the next major release. Use a local converter.\n",
      "  warnings.warn('The global conversion available with activate() '\n",
      "/Users/tadeoye/miniconda3/envs/scRNA_seq_meta_analysis/lib/python3.10/site-packages/rpy2/robjects/conversion.py:28: DeprecationWarning: The use of converter in module rpy2.robjects.conversion is deprecated. Use rpy2.robjects.conversion.get_conversion() instead of rpy2.robjects.conversion.converter.\n",
      "  warnings.warn(\n",
      "/Users/tadeoye/miniconda3/envs/scRNA_seq_meta_analysis/lib/python3.10/site-packages/rpy2/robjects/pandas2ri.py:368: DeprecationWarning: The global conversion available with activate() is deprecated and will be removed in the next major release. Use a local converter.\n",
      "  warnings.warn('The global conversion available with activate() '\n",
      "/Users/tadeoye/miniconda3/envs/scRNA_seq_meta_analysis/lib/python3.10/site-packages/rpy2/robjects/numpy2ri.py:241: DeprecationWarning: The global conversion available with activate() is deprecated and will be removed in the next major release. Use a local converter.\n",
      "  warnings.warn('The global conversion available with activate() '\n",
      "/Users/tadeoye/miniconda3/envs/scRNA_seq_meta_analysis/lib/python3.10/site-packages/rpy2/robjects/conversion.py:28: DeprecationWarning: The use of converter in module rpy2.robjects.conversion is deprecated. Use rpy2.robjects.conversion.get_conversion() instead of rpy2.robjects.conversion.converter.\n",
      "  warnings.warn(\n",
      "/Users/tadeoye/miniconda3/envs/scRNA_seq_meta_analysis/lib/python3.10/site-packages/rpy2/robjects/pandas2ri.py:368: DeprecationWarning: The global conversion available with activate() is deprecated and will be removed in the next major release. Use a local converter.\n",
      "  warnings.warn('The global conversion available with activate() '\n",
      "/Users/tadeoye/miniconda3/envs/scRNA_seq_meta_analysis/lib/python3.10/site-packages/rpy2/robjects/numpy2ri.py:241: DeprecationWarning: The global conversion available with activate() is deprecated and will be removed in the next major release. Use a local converter.\n",
      "  warnings.warn('The global conversion available with activate() '\n",
      "/Users/tadeoye/miniconda3/envs/scRNA_seq_meta_analysis/lib/python3.10/site-packages/rpy2/robjects/conversion.py:28: DeprecationWarning: The use of converter in module rpy2.robjects.conversion is deprecated. Use rpy2.robjects.conversion.get_conversion() instead of rpy2.robjects.conversion.converter.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%%R -o pseudobulk_strategy_list\n",
    "\n",
    "#Transforming the nGene and nUMI\n",
    "pseudobulk_strategy_list <- list()\n",
    "\n",
    "for (strategy in pseudobulking_strategies){\n",
    "    pseudobulk_strategy[[strategy]]$QC_Gene_total_log=log2(pseudobulk_strategy[[strategy]]$QC_Gene_total_count)\n",
    "    pseudobulk_strategy[[strategy]]$QC_Gene_unique_log=log2(pseudobulk_strategy[[strategy]]$QC_Gene_unique_count)\n",
    "\n",
    "    #spliting the objects based on the cluster annotations\n",
    "    pseudobulk_strategy_list[[strategy]] = .mySplitObject(pseudobulk_strategy[[strategy]], 'cell_type')\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99b2c2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for strategy in pseudobulking_strategies:\n",
    "    for cell_type in celltypes:\n",
    "        try:\n",
    "            pseudobulk_strategy_list[strategy][cell_type].layers['counts'] = pseudobulk_strategy_list[strategy][cell_type].X.copy()\n",
    "        except KeyError:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff70c9a",
   "metadata": {},
   "source": [
    "Next, we perform DE analysis using specified method's in limma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8cff8483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert nested list of Seurat object into Rpy2 object \n",
    "\n",
    "pseudobulk_strategy_list =  robjects.ListVector(\n",
    "                                    {\n",
    "                                        strategy: robjects.ListVector(\n",
    "                                                    {\n",
    "                                                        cell_type: pseudobulk_strategy_list[strategy][cell_type]\n",
    "                                                \n",
    "                                                        for cell_type in pseudobulk_strategy_list[strategy].keys()\n",
    "                                                    }\n",
    "                                                )\n",
    "                                        for strategy in pseudobulking_strategies\n",
    "                                    }    \n",
    "                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bf0e09",
   "metadata": {},
   "source": [
    "#### **Estimating DEGS in Pseudocells with Network Aggregation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ff5f732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Functions:\n",
      ".myRead10X()\n",
      ".myRead10X_h5()\n",
      ".myLigerToExpSet()\n",
      ".mycBindFn()\n",
      ".myExpSetCreatorFn()\n",
      ".myIntegrative_oneline()\n",
      ".myFindAllMarkers()\n",
      ".myAnnotateFn()\n",
      ".my2dPlot()\n",
      ".myPseudoCellfn_v2()\n",
      ".myLabelTransfer_harmony()\n",
      ".myLabelTransfer_liger()\n",
      ".myMapToHuman()\n",
      ".myRiverPlotFn()\n",
      ".myClusteringOptimizerFn()\n",
      ".myMarkerBasedAnalysisFn()\n",
      ".mycellAssignHeatmap()\n",
      ".myMetaMarkerFn()\n",
      ".myFindNeighbors()\n",
      ".myVlnPlot()\n",
      ".myFeaturePlot()\n",
      ".myheatmap.3()\n",
      ".myEvalMarkers()\n",
      ".myReadGMT()\n",
      ".mySplitObject()\n",
      ".myRTNgsea(two-sided GSEA implementation)\n",
      "[1] \"Estimating DEGs using Trend\"\n",
      "[1] \"Calculating DE genes for OPC\"\n",
      "[1] \"Number of expressed genes: 17558\"\n",
      "[1] \"............................\"\n",
      "[1] \"............................\"\n"
     ]
    }
   ],
   "source": [
    "%%R -i pseudobulk_strategy_list -i covariates -i filter_genes -i gene_celltype_threshold -i deg_methods_to_run -i normalization_methods -i randomEffect\n",
    "\n",
    "source(\"../scripts/functions/deg_functions/sconline_code.R\")\n",
    "\n",
    "########### Setting the parameters ################\n",
    "\n",
    "# The column names for covariates to be included in the analysis including the main effect\n",
    "covList = covariates\n",
    "# background genes used for differntial expression testing. \n",
    "# usually set to genes expressed in >1% of cells. default: NULL\n",
    "if (filter_genes){\n",
    "    bkg_gene_pct_thr = gene_celltype_threshold # selecting genes that are expressed in > 10% of cells\n",
    "    bkg_gene_count_thr = 10\n",
    "} else{\n",
    "    bkg_gene_pct_thr = NULL\n",
    "}\n",
    "# The column name for the random effect (it is donor id in most scenarios).\n",
    "# Set to NULL for pseudobulk data\n",
    "rand_var = randomEffect\n",
    "# whether or not to do quantile normalization on the normalized data. default: F. \n",
    "# Specially useful if the highly expressed genes like MALAT1 are being identified as differentially expressed.\n",
    "quantile_norm = T\n",
    "\n",
    "DE_results <- list()\n",
    "\n",
    "if ('network' %in% pseudobulking_strategies){\n",
    "\n",
    "  DE_results[['network']] <- list()\n",
    "\n",
    "  for (de_method in deg_methods_to_run){\n",
    "\n",
    "    DE_results[['network']][[de_method]] <- list()\n",
    "\n",
    "    for (norm_method in normalization_methods){\n",
    "\n",
    "      print(paste0('Estimating DEGs using ', de_method))\n",
    "      #DE res on pseudobulk_strategy[['random']] per cluster\n",
    "      results = lapply(names(pseudobulk_strategy_list[['network']]),function(x_name){\n",
    "\n",
    "          x = pseudobulk_strategy_list[['network']][[x_name]]\n",
    "          res_arranged = NULL\n",
    "\n",
    "          #requiring existence of at least 6 pseudocells for the DE analysis\n",
    "          if(length(unique(x$pathology.group))>1&ncol(x)>5){\n",
    "            print(paste0(\"Calculating DE genes for \", x_name))\n",
    "            \n",
    "            num_early = table(x$pathology.group)['early']\n",
    "            num_late = table(x$pathology.group)['late']\n",
    "            num_no = table(x$pathology.group)['no']\n",
    "\n",
    "            frac_early = num_early/(num_early + num_late)\n",
    "            frac_late = num_late/(num_early + num_late)\n",
    "\n",
    "            if(!is.null(bkg_gene_pct_thr)){\n",
    "                #background genes should be selectd based on the cell level expression data\n",
    "              tmp_bkg_genes = counts(adata_annot)[,which(adata_annot$cell_type==x_name)]\n",
    "              tmp_bkg_genes_counts=rowSums(tmp_bkg_genes>0)\n",
    "              tmp_bkg_genes_frac=tmp_bkg_genes_counts/sum(adata_annot$cell_type==x_name)\n",
    "              tmp_bkg_genes=row.names(adata_annot)[tmp_bkg_genes_frac>=bkg_gene_pct_thr&tmp_bkg_genes_counts>=bkg_gene_count_thr]\n",
    "              \n",
    "            } else {\n",
    "              tmp_bkg_genes=NULL\n",
    "            }\n",
    "    \n",
    "            #inputExpData=x;covariates=covList;randomEffect=rand_effect;bkg_genes=tmp_bkg_genes;quantile.norm=quantile_norm;prior.count=1\n",
    "            res =.sconline.fitLimmaFn(inputExpData=x,\n",
    "                                    covariates=covList,\n",
    "                                    randomEffect = rand_var,\n",
    "                                    bkg_genes = tmp_bkg_genes,\n",
    "                                    quantile.norm = quantile_norm,\n",
    "                                    prior.count = 1,\n",
    "                                    DEmethod = de_method,\n",
    "                                    normalization = norm_method)\n",
    "            #check the dc object, the usual consensus.correlation that I get is in the range of ~0.2 or above if rand=T\n",
    "            \n",
    "            \n",
    "            if(sum(grepl(\"pathology.group\", colnames(res$model)))>0){\n",
    "              #Defining the comparisosn that we are interested in to know it's logFC and pval\n",
    "              # Now, use this in makeContrasts\n",
    "              contr <- makeContrasts(\n",
    "                  pathology.groupearly - pathology.groupno,\n",
    "                  pathology.grouplate - pathology.groupno,\n",
    "                  pathology.grouplate - pathology.groupearly,\n",
    "                  (pathology.groupearly + pathology.grouplate)/2 - pathology.groupno,\n",
    "                  levels = res$model\n",
    "                  )\n",
    "              \n",
    "              fit2=contrasts.fit(res$fit, contrasts=contr)\n",
    "              #Explore setting robust=F\n",
    "              fit2=eBayes(fit2,robust = T,trend=T)\n",
    "              #running topTable for each contrast\n",
    "              res_early=topTable(fit2,number=dim(fit2)[1], adjust.method = \"BH\", coef=\"pathology.groupearly - pathology.groupno\");\n",
    "              res_late=topTable(fit2,number=dim(fit2)[1], adjust.method = \"BH\", coef=\"pathology.grouplate - pathology.groupno\");\n",
    "              res_lve=topTable(fit2,number=dim(fit2)[1], adjust.method = \"BH\", coef=\"pathology.grouplate - pathology.groupearly\");\n",
    "              res_ad=topTable(fit2,number=dim(fit2)[1], adjust.method = \"BH\", coef=\"(pathology.groupearly + pathology.grouplate)/2 - pathology.groupno\");\n",
    "              \n",
    "              res_early$gene=row.names(res_early)\n",
    "              res_late$gene=row.names(res_early)\n",
    "              res_ad$gene=row.names(res_ad)\n",
    "              res_lve$gene=row.names(res_lve)\n",
    "\n",
    "              colnames(res_early)=paste0(\"early.\",colnames(res_early))\n",
    "              colnames(res_late)=paste0(\"late.\",colnames(res_late))\n",
    "              colnames(res_ad)=paste0(\"ad.\",colnames(res_ad))\n",
    "              colnames(res_lve)=paste0(\"lve.\",colnames(res_lve))\n",
    "\n",
    "              # Merge res_early and res_late\n",
    "              merged_early_late <- merge(res_early, res_late, by.x=\"early.gene\", by.y=\"late.gene\", all=TRUE)\n",
    "              merged_lve <- merge(merged_early_late, res_lve, by.x=\"early.gene\", by.y=\"lve.gene\", all=TRUE)\n",
    "              merged_all <- merge(merged_lve, res_ad, by.x=\"early.gene\", by.y=\"ad.gene\", all=TRUE)\n",
    "              \n",
    "              res_arranged <- merged_all\n",
    "\n",
    "              res_arranged$blocked_analysis=res$blocked_analysis\n",
    "              res_arranged$block.cor=res$dc$consensus.correlation #check the dc object, the usual consensus.correlation range is ~0.2 or above if rand=T\n",
    "              res_arranged$cell_type=unique(as.character(x$cell_type))\n",
    "              colnames(res_arranged)[colnames(res_arranged)==\"early.gene\"]=\"gene\"\n",
    "            }\n",
    "          }\n",
    "        return(res_arranged)\n",
    "      })\n",
    "\n",
    "      # Naming the list entries\n",
    "      named_results <- setNames(results, names(pseudobulk_strategy_list[['network']]))\n",
    "\n",
    "      # Storing the named results in DE_results[['network']]\n",
    "      DE_results[['network']][[de_method]][[norm_method]] <- named_results\n",
    "\n",
    "    }\n",
    "\n",
    "    print('............................')\n",
    "    print('............................')\n",
    "\n",
    "  }\n",
    "\n",
    "} else {\n",
    "  DE_results[['network']] <- NULL\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016d5dfe",
   "metadata": {},
   "source": [
    "#### **Estimating DEGS in Pseudocells with Random Aggregation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4880e0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Estimating DEGs using Trend\"\n",
      "[1] \"Calculating DE genes for OPC\"\n",
      "[1] \"Number of expressed genes: 17558\"\n",
      "[1] \"............................\"\n",
      "[1] \"............................\"\n"
     ]
    }
   ],
   "source": [
    "%%R \n",
    "\n",
    "########### Setting the parameters ################\n",
    "\n",
    "# The column names for covariates to be included in the analysis including the main effect\n",
    "covList = covariates\n",
    "# background genes used for differntial expression testing. \n",
    "# usually set to genes expressed in >1% of cells. default: NULL\n",
    "if (filter_genes){\n",
    "    bkg_gene_pct_thr = gene_celltype_threshold # selecting genes that are expressed in > 10% of cells\n",
    "    bkg_gene_count_thr = 10\n",
    "} else{\n",
    "    bkg_gene_pct_thr = NULL\n",
    "}\n",
    "# The column name for the random effect (it is donor id in most scenarios).\n",
    "# Set to NULL for pseudobulk data\n",
    "rand_var = randomEffect\n",
    "# whether or not to do quantile normalization on the normalized data. default: F. \n",
    "# Specially useful if the highly expressed genes like MALAT1 are being identified as differentially expressed.\n",
    "quantile_norm = T\n",
    "\n",
    "if ('random' %in% pseudobulking_strategies){\n",
    "\n",
    "  for (de_method in deg_methods_to_run){\n",
    "\n",
    "    DE_results[['random']][[de_method]] <- list()\n",
    "\n",
    "    for (norm_method in normalization_methods){\n",
    "\n",
    "      print(paste0('Estimating DEGs using ', de_method))\n",
    "      #DE res on pseudobulk_strategy[['random']] per cluster\n",
    "      results = lapply(names(pseudobulk_strategy_list[['random']]),function(x_name){\n",
    "\n",
    "          x = pseudobulk_strategy_list[['random']][[x_name]]\n",
    "          res_arranged = NULL\n",
    "\n",
    "          #requiring existence of at least 6 pseudocells for the DE analysis\n",
    "          if(length(unique(x$pathology.group))>1&ncol(x)>5){\n",
    "            print(paste0(\"Calculating DE genes for \", x_name))\n",
    "            \n",
    "            num_early = table(x$pathology.group)['early']\n",
    "            num_late = table(x$pathology.group)['late']\n",
    "            num_no = table(x$pathology.group)['no']\n",
    "\n",
    "            frac_early = num_early/(num_early + num_late)\n",
    "            frac_late = num_late/(num_early + num_late)\n",
    "\n",
    "            if(!is.null(bkg_gene_pct_thr)){\n",
    "                #background genes should be selectd based on the cell level expression data\n",
    "              tmp_bkg_genes = counts(adata_annot)[,which(adata_annot$cell_type==x_name)]\n",
    "              tmp_bkg_genes_counts=rowSums(tmp_bkg_genes>0)\n",
    "              tmp_bkg_genes_frac=tmp_bkg_genes_counts/sum(adata_annot$cell_type==x_name)\n",
    "              tmp_bkg_genes=row.names(adata_annot)[tmp_bkg_genes_frac>=bkg_gene_pct_thr&tmp_bkg_genes_counts>=bkg_gene_count_thr]\n",
    "              \n",
    "            } else {\n",
    "              tmp_bkg_genes=NULL\n",
    "            }\n",
    "    \n",
    "\n",
    "            #inputExpData=x;covariates=covList;randomEffect=rand_effect;bkg_genes=tmp_bkg_genes;quantile.norm=quantile_norm;prior.count=1\n",
    "            res =.sconline.fitLimmaFn(inputExpData=x,\n",
    "                                    covariates=covList,\n",
    "                                    randomEffect = rand_var,\n",
    "                                    bkg_genes = tmp_bkg_genes,\n",
    "                                    quantile.norm = quantile_norm,\n",
    "                                    prior.count = 1,\n",
    "                                    DEmethod = de_method,\n",
    "                                    normalization = norm_method)\n",
    "            #check the dc object, the usual consensus.correlation that I get is in the range of ~0.2 or above if rand=T\n",
    "            \n",
    "            \n",
    "            if(sum(grepl(\"pathology.group\", colnames(res$model)))>0){\n",
    "              #Defining the comparisosn that we are interested in to know it's logFC and pval\n",
    "              # Now, use this in makeContrasts\n",
    "              contr <- makeContrasts(\n",
    "                  pathology.groupearly - pathology.groupno,\n",
    "                  pathology.grouplate - pathology.groupno,\n",
    "                  pathology.grouplate - pathology.groupearly,\n",
    "                  (pathology.groupearly + pathology.grouplate)/2 - pathology.groupno,\n",
    "                  levels = res$model\n",
    "                  )\n",
    "              \n",
    "              fit2=contrasts.fit(res$fit, contrasts=contr)\n",
    "              #Explore setting robust=F\n",
    "              fit2=eBayes(fit2,robust = T,trend=T)\n",
    "              #running topTable for each contrast\n",
    "              res_early=topTable(fit2,number=dim(fit2)[1], adjust.method = \"BH\", coef=\"pathology.groupearly - pathology.groupno\");\n",
    "              res_late=topTable(fit2,number=dim(fit2)[1], adjust.method = \"BH\", coef=\"pathology.grouplate - pathology.groupno\");\n",
    "              res_lve=topTable(fit2,number=dim(fit2)[1], adjust.method = \"BH\", coef=\"pathology.grouplate - pathology.groupearly\");\n",
    "              res_ad=topTable(fit2,number=dim(fit2)[1], adjust.method = \"BH\", coef=\"(pathology.groupearly + pathology.grouplate)/2 - pathology.groupno\");\n",
    "              \n",
    "              res_early$gene=row.names(res_early)\n",
    "              res_late$gene=row.names(res_early)\n",
    "              res_ad$gene=row.names(res_ad)\n",
    "              res_lve$gene=row.names(res_lve)\n",
    "\n",
    "              colnames(res_early)=paste0(\"early.\",colnames(res_early))\n",
    "              colnames(res_late)=paste0(\"late.\",colnames(res_late))\n",
    "              colnames(res_ad)=paste0(\"ad.\",colnames(res_ad))\n",
    "              colnames(res_lve)=paste0(\"lve.\",colnames(res_lve))\n",
    "\n",
    "              # Merge res_early and res_late\n",
    "              merged_early_late <- merge(res_early, res_late, by.x=\"early.gene\", by.y=\"late.gene\", all=TRUE)\n",
    "              merged_lve <- merge(merged_early_late, res_lve, by.x=\"early.gene\", by.y=\"lve.gene\", all=TRUE)\n",
    "              merged_all <- merge(merged_lve, res_ad, by.x=\"early.gene\", by.y=\"ad.gene\", all=TRUE)\n",
    "              \n",
    "              res_arranged <- merged_all\n",
    "\n",
    "              res_arranged$blocked_analysis=res$blocked_analysis\n",
    "              res_arranged$block.cor=res$dc$consensus.correlation #check the dc object, the usual consensus.correlation range is ~0.2 or above if rand=T\n",
    "              res_arranged$cell_type=unique(as.character(x$cell_type))\n",
    "              colnames(res_arranged)[colnames(res_arranged)==\"early.gene\"]=\"gene\"\n",
    "            }\n",
    "            \n",
    "          }\n",
    "        return(res_arranged)\n",
    "      })\n",
    "\n",
    "      # Naming the list entries\n",
    "      named_results <- setNames(results, names(pseudobulk_strategy_list[['random']]))\n",
    "\n",
    "      # Storing the named results in DE_results[['network']]\n",
    "      DE_results[['random']][[de_method]][[norm_method]] <- named_results\n",
    "    }\n",
    "\n",
    "    print('............................')\n",
    "    print('............................')\n",
    "\n",
    "  }\n",
    "\n",
    "} else{\n",
    "\n",
    "DE_results[['random']] <- NULL\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a48d534",
   "metadata": {},
   "source": [
    "#### **Estimating DEGS in Pseudocells with Smaller Size**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2cdeb3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "########### Setting the parameters ################\n",
    "\n",
    "# The column names for covariates to be included in the analysis including the main effect\n",
    "covList = covariates\n",
    "# background genes used for differntial expression testing. \n",
    "# usually set to genes expressed in >1% of cells. default: NULL\n",
    "if (filter_genes){\n",
    "    bkg_gene_pct_thr = gene_celltype_threshold # selecting genes that are expressed in > 10% of cells\n",
    "    bkg_gene_count_thr = 10\n",
    "} else{\n",
    "    bkg_gene_pct_thr = NULL\n",
    "}\n",
    "# The column name for the random effect (it is donor id in most scenarios).\n",
    "# Set to NULL for pseudobulk data\n",
    "rand_var = randomEffect\n",
    "# whether or not to do quantile normalization on the normalized data. default: F. \n",
    "# Specially useful if the highly expressed genes like MALAT1 are being identified as differentially expressed.\n",
    "quantile_norm = T\n",
    "\n",
    "\n",
    "if ('smaller network' %in% pseudobulking_strategies){\n",
    "\n",
    "  for (de_method in deg_methods_to_run){\n",
    "\n",
    "    DE_results[['smaller network']][[de_method]] <- list()\n",
    "\n",
    "    for (norm_method in normalization_methods){\n",
    "\n",
    "      print(paste0('Estimating DEGs using ', de_method))\n",
    "      #DE res on pseudobulk_strategy[['random']] per cluster\n",
    "      results = lapply(names(pseudobulk_strategy_list[['smaller network']]),function(x_name){\n",
    "\n",
    "          x = pseudobulk_strategy_list[['smaller network']][[x_name]]\n",
    "          res_arranged = NULL\n",
    "\n",
    "          #requiring existence of at least 6 pseudocells for the DE analysis\n",
    "          if(length(unique(x$pathology.group))>1&ncol(x)>5){\n",
    "            print(paste0(\"Calculating DE genes for \", x_name))\n",
    "            \n",
    "            num_early = table(x$pathology.group)['early']\n",
    "            num_late = table(x$pathology.group)['late']\n",
    "            num_no = table(x$pathology.group)['no']\n",
    "\n",
    "            frac_early = num_early/(num_early + num_late)\n",
    "            frac_late = num_late/(num_early + num_late)\n",
    "\n",
    "            if(!is.null(bkg_gene_pct_thr)){\n",
    "                #background genes should be selectd based on the cell level expression data\n",
    "              tmp_bkg_genes = counts(adata_annot)[,which(adata_annot$cell_type==x_name)]\n",
    "              tmp_bkg_genes_counts=rowSums(tmp_bkg_genes>0)\n",
    "              tmp_bkg_genes_frac=tmp_bkg_genes_counts/sum(adata_annot$cell_type==x_name)\n",
    "              tmp_bkg_genes=row.names(adata_annot)[tmp_bkg_genes_frac>=bkg_gene_pct_thr&tmp_bkg_genes_counts>=bkg_gene_count_thr]\n",
    "              \n",
    "            } else {\n",
    "              tmp_bkg_genes=NULL\n",
    "            }\n",
    "    \n",
    "\n",
    "            #inputExpData=x;covariates=covList;randomEffect=rand_effect;bkg_genes=tmp_bkg_genes;quantile.norm=quantile_norm;prior.count=1\n",
    "            res =.sconline.fitLimmaFn(inputExpData=x,\n",
    "                                    covariates=covList,\n",
    "                                    randomEffect = rand_var,\n",
    "                                    bkg_genes = tmp_bkg_genes,\n",
    "                                    quantile.norm = quantile_norm,\n",
    "                                    prior.count = 1,\n",
    "                                    DEmethod = de_method,\n",
    "                                    normalization = norm_method)\n",
    "            #check the dc object, the usual consensus.correlation that I get is in the range of ~0.2 or above if rand=T\n",
    "            \n",
    "            \n",
    "            if(sum(grepl(\"pathology.group\", colnames(res$model)))>0){\n",
    "              #Defining the comparisosn that we are interested in to know it's logFC and pval\n",
    "              # Now, use this in makeContrasts\n",
    "              contr <- makeContrasts(\n",
    "                  pathology.groupearly - pathology.groupno,\n",
    "                  pathology.grouplate - pathology.groupno,\n",
    "                  pathology.grouplate - pathology.groupearly,\n",
    "                  (pathology.groupearly + pathology.grouplate)/2 - pathology.groupno,\n",
    "                  levels = res$model\n",
    "                  )\n",
    "              \n",
    "              fit2=contrasts.fit(res$fit, contrasts=contr)\n",
    "              #Explore setting robust=F\n",
    "              fit2=eBayes(fit2,robust = T,trend=T)\n",
    "              #running topTable for each contrast\n",
    "              res_early=topTable(fit2,number=dim(fit2)[1], adjust.method = \"BH\", coef=\"pathology.groupearly - pathology.groupno\");\n",
    "              res_late=topTable(fit2,number=dim(fit2)[1], adjust.method = \"BH\", coef=\"pathology.grouplate - pathology.groupno\");\n",
    "              res_lve=topTable(fit2,number=dim(fit2)[1], adjust.method = \"BH\", coef=\"pathology.grouplate - pathology.groupearly\");\n",
    "              res_ad=topTable(fit2,number=dim(fit2)[1], adjust.method = \"BH\", coef=\"(pathology.groupearly + pathology.grouplate)/2 - pathology.groupno\");\n",
    "              \n",
    "              res_early$gene=row.names(res_early)\n",
    "              res_late$gene=row.names(res_early)\n",
    "              res_ad$gene=row.names(res_ad)\n",
    "              res_lve$gene=row.names(res_lve)\n",
    "\n",
    "              colnames(res_early)=paste0(\"early.\",colnames(res_early))\n",
    "              colnames(res_late)=paste0(\"late.\",colnames(res_late))\n",
    "              colnames(res_ad)=paste0(\"ad.\",colnames(res_ad))\n",
    "              colnames(res_lve)=paste0(\"lve.\",colnames(res_lve))\n",
    "\n",
    "              # Merge res_early and res_late\n",
    "              merged_early_late <- merge(res_early, res_late, by.x=\"early.gene\", by.y=\"late.gene\", all=TRUE)\n",
    "              merged_lve <- merge(merged_early_late, res_lve, by.x=\"early.gene\", by.y=\"lve.gene\", all=TRUE)\n",
    "              merged_all <- merge(merged_lve, res_ad, by.x=\"early.gene\", by.y=\"ad.gene\", all=TRUE)\n",
    "              \n",
    "              res_arranged <- merged_all\n",
    "\n",
    "              res_arranged$blocked_analysis=res$blocked_analysis\n",
    "              res_arranged$block.cor=res$dc$consensus.correlation #check the dc object, the usual consensus.correlation range is ~0.2 or above if rand=T\n",
    "              res_arranged$cell_type=unique(as.character(x$cell_type))\n",
    "              colnames(res_arranged)[colnames(res_arranged)==\"early.gene\"]=\"gene\"\n",
    "            }\n",
    "          }\n",
    "        return(res_arranged)\n",
    "      })\n",
    "\n",
    "      # Naming the list entries\n",
    "      named_results <- setNames(results, names(pseudobulk_strategy_list[['smaller network']]))\n",
    "\n",
    "      # Storing the named results in DE_results[['network']]\n",
    "      DE_results[['smaller network']][[de_method]][[norm_method]] <- named_results\n",
    "    }\n",
    "\n",
    "    print('............................')\n",
    "    print('............................')\n",
    "  }\n",
    "  \n",
    "} else {\n",
    "\n",
    "  DE_results[['smaller network']] <- NULL\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc5029e",
   "metadata": {},
   "source": [
    "#### **Estimating DEGS in Pseudocells with Standard Pseudobulking**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ed6c2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Estimating DEGs using Trend\"\n",
      "[1] \"Calculating DE genes for OPC\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Number of expressed genes: 17558\"\n",
      "[1] \"............................\"\n",
      "[1] \"............................\"\n"
     ]
    }
   ],
   "source": [
    "%%R \n",
    "\n",
    "########### Setting the parameters ################\n",
    "\n",
    "# The column names for covariates to be included in the analysis including the main effect\n",
    "covList = covariates\n",
    "# background genes used for differntial expression testing. \n",
    "# usually set to genes expressed in >1% of cells. default: NULL\n",
    "if (filter_genes){\n",
    "    bkg_gene_pct_thr = gene_celltype_threshold # selecting genes that are expressed in > 10% of cells\n",
    "    bkg_gene_count_thr = 10\n",
    "} else{\n",
    "    bkg_gene_pct_thr = NULL\n",
    "}\n",
    "# The column name for the random effect (it is donor id in most scenarios).\n",
    "# Set to NULL for pseudobulk data\n",
    "rand_var = randomEffect\n",
    "# whether or not to do quantile normalization on the normalized data. default: F. \n",
    "# Specially useful if the highly expressed genes like MALAT1 are being identified as differentially expressed.\n",
    "quantile_norm = T\n",
    "\n",
    "\n",
    "\n",
    "if ('bulk' %in% pseudobulking_strategies){\n",
    "\n",
    "  for (de_method in deg_methods_to_run){\n",
    "\n",
    "    DE_results[['bulk']][[de_method]] <- list()\n",
    "\n",
    "    for (norm_method in normalization_methods){\n",
    "\n",
    "      print(paste0('Estimating DEGs using ', de_method))\n",
    "      #DE res on pseudobulk_strategy[['random']] per cluster\n",
    "      results = lapply(names(pseudobulk_strategy_list[['bulk']]),function(x_name){\n",
    "\n",
    "          x = pseudobulk_strategy_list[['bulk']][[x_name]]\n",
    "          res_arranged = NULL\n",
    "\n",
    "          #requiring existence of at least 6 pseudocells for the DE analysis\n",
    "          if(length(unique(x$pathology.group))>1&ncol(x)>5){\n",
    "            print(paste0(\"Calculating DE genes for \", x_name))\n",
    "            \n",
    "            num_early = table(x$pathology.group)['early']\n",
    "            num_late = table(x$pathology.group)['late']\n",
    "            num_no = table(x$pathology.group)['no']\n",
    "\n",
    "            frac_early = num_early/(num_early + num_late)\n",
    "            frac_late = num_late/(num_early + num_late)\n",
    "\n",
    "            if(!is.null(bkg_gene_pct_thr)){\n",
    "                #background genes should be selectd based on the cell level expression data\n",
    "              tmp_bkg_genes = counts(adata_annot)[,which(adata_annot$cell_type==x_name)]\n",
    "              tmp_bkg_genes_counts=rowSums(tmp_bkg_genes>0)\n",
    "              tmp_bkg_genes_frac=tmp_bkg_genes_counts/sum(adata_annot$cell_type==x_name)\n",
    "              tmp_bkg_genes=row.names(adata_annot)[tmp_bkg_genes_frac>=bkg_gene_pct_thr&tmp_bkg_genes_counts>=bkg_gene_count_thr]\n",
    "              \n",
    "            } else {\n",
    "              tmp_bkg_genes=NULL\n",
    "            }\n",
    "            #inputExpData=x;covariates=covList;randomEffect=rand_effect;bkg_genes=tmp_bkg_genes;quantile.norm=quantile_norm;prior.count=1\n",
    "            res =.sconline.fitLimmaFn(inputExpData=x,\n",
    "                                    covariates=covList,\n",
    "                                    randomEffect = NULL,\n",
    "                                    bkg_genes = tmp_bkg_genes,\n",
    "                                    quantile.norm = quantile_norm,\n",
    "                                    prior.count = 1,\n",
    "                                    DEmethod = de_method,\n",
    "                                    normalization = norm_method)\n",
    "            #check the dc object, the usual consensus.correlation that I get is in the range of ~0.2 or above if rand=T\n",
    "                      \n",
    "            if(sum(grepl(\"pathology.group\", colnames(res$model)))>0){\n",
    "              #Defining the comparisosn that we are interested in to know it's logFC and pval\n",
    "              # Now, use this in makeContrasts\n",
    "              contr <- makeContrasts(\n",
    "                  pathology.groupearly - pathology.groupno,\n",
    "                  pathology.grouplate - pathology.groupno,\n",
    "                  pathology.grouplate - pathology.groupearly,\n",
    "                  (pathology.groupearly + pathology.grouplate)/2 - pathology.groupno,\n",
    "                  levels = res$model\n",
    "                  )\n",
    "              \n",
    "              fit2=contrasts.fit(res$fit, contrasts=contr)\n",
    "              #Explore setting robust=F\n",
    "              fit2=eBayes(fit2,robust = T,trend=T)\n",
    "              #running topTable for each contrast\n",
    "              res_early=topTable(fit2,number=dim(fit2)[1], adjust.method = \"BH\", coef=\"pathology.groupearly - pathology.groupno\");\n",
    "              res_late=topTable(fit2,number=dim(fit2)[1], adjust.method = \"BH\", coef=\"pathology.grouplate - pathology.groupno\");\n",
    "              res_lve=topTable(fit2,number=dim(fit2)[1], adjust.method = \"BH\", coef=\"pathology.grouplate - pathology.groupearly\");\n",
    "              res_ad=topTable(fit2,number=dim(fit2)[1], adjust.method = \"BH\", coef=\"(pathology.groupearly + pathology.grouplate)/2 - pathology.groupno\");\n",
    "            \n",
    "\n",
    "              res_early$gene=row.names(res_early)\n",
    "              res_late$gene=row.names(res_early)\n",
    "              res_ad$gene=row.names(res_ad)\n",
    "              res_lve$gene=row.names(res_lve)\n",
    "\n",
    "              colnames(res_early)=paste0(\"early.\",colnames(res_early))\n",
    "              colnames(res_late)=paste0(\"late.\",colnames(res_late))\n",
    "              colnames(res_ad)=paste0(\"ad.\",colnames(res_ad))\n",
    "              colnames(res_lve)=paste0(\"lve.\",colnames(res_lve))\n",
    "\n",
    "              # Merge res_early and res_late\n",
    "              merged_early_late <- merge(res_early, res_late, by.x=\"early.gene\", by.y=\"late.gene\", all=TRUE)\n",
    "              merged_lve <- merge(merged_early_late, res_lve, by.x=\"early.gene\", by.y=\"lve.gene\", all=TRUE)\n",
    "              merged_all <- merge(merged_lve, res_ad, by.x=\"early.gene\", by.y=\"ad.gene\", all=TRUE)\n",
    "              \n",
    "              res_arranged <- merged_all\n",
    "\n",
    "              res_arranged$blocked_analysis=res$blocked_analysis\n",
    "              res_arranged$cell_type=unique(as.character(x$cell_type))\n",
    "              colnames(res_arranged)[colnames(res_arranged)==\"early.gene\"]=\"gene\"\n",
    "\n",
    "\n",
    "            }\n",
    "          }\n",
    "        return(res_arranged)\n",
    "      })\n",
    "\n",
    "      # Naming the list entries\n",
    "      named_results <- setNames(results, names(pseudobulk_strategy_list[['bulk']]))\n",
    "\n",
    "      # Storing the named results in DE_results[['network']]\n",
    "      DE_results[['bulk']][[de_method]][[norm_method]] <- named_results\n",
    "    }\n",
    "\n",
    "    print('............................')\n",
    "    print('............................')\n",
    "\n",
    "  }\n",
    "\n",
    "} else {\n",
    "\n",
    "  DE_results[['bulk']] <- NULL\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7f9f6d",
   "metadata": {},
   "source": [
    "### **Robustness analysis**\n",
    "\n",
    "Robustness analysis provides an orthogonal support for the identified DE genes. In addition to being an independent approach from the DE analysis method, `robustness scores are also not affected by the covariates,` making it a simple, `intuitive way to assess our confidence on the DE genes`. \n",
    "\n",
    "Briefly, robustness score is `defined as the fraction of samples in the experiment that show an up or down regulation pattern across control condition`. For example, if we have 4 Abeta donors and 5 Ctrl donors, robustness score for each gene is calculated by comparing cells from each of Abeta donors with cells from each of Ctrl (e.g., 4 x 5 = 20 comparisons). Robustness scores are scaled to be between -1 to 1. score of 1 (-1) indicate a gene is consistently up (down) regulated in every experiment donor compared to every control. Similarly, a robustness score of 0 indicate a gene is randomly up/down regulated across experiment donors.\n",
    "\n",
    "We perform robustness analysis by using function provided in code by [Gazestani. et. al. 2023](https://www.sciencedirect.com/science/article/pii/S0092867423008590?via%3Dihub). The default robustness score threshold of 0.6 means that a gene is consistently up or down regulated in at least 80% of comparisons. Note that for thresholding on the robustness scores, absolute values should be used. Moreover, since robustness scores are not affected by the DE method, we don't need to repeat it's calculation everytime that we change the pseudocell/pseudobulk strategy or alter the list of covariates. It needs to be calculated only once per dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bff0a196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%R\n",
    "\n",
    "# #A sample function to calculate robustness scores for earl, late, ad test conditions compared to controls\n",
    "# .robustness_scoresfn = function(input_exp_data){\n",
    "\n",
    "#   # Filter out columns with NA cell_type values\n",
    "#   res_robustness=list()\n",
    "#     input_exp_data=input_exp_data[,!is.na(input_exp_data$cell_type)]\n",
    "\n",
    "#   # Loop through each unique cell type to compute robustness scores\n",
    "#   for(iclust in unique(input_exp_data$cell_type)){\n",
    "#     print(paste0(\"Calculating robustness for \",iclust))\n",
    "\n",
    "#     # Extract data for the current cell type\n",
    "#     tmp_data=input_exp_data[,which(input_exp_data$cell_type==iclust)]\n",
    "#     # Convert the extracted data to Seurat format and normalize it\n",
    "#     tmp_data_seurat =.extraExport2SeuratFn(inputData=tmp_data, project=\"scRNA\")\n",
    "#     tmp_data_seurat = Seurat::NormalizeData(tmp_data_seurat, verbose=F)\n",
    "\n",
    "#     # If the data contains both \"early\" and \"no\" status values, calculate robustness for early\n",
    "#     if(sum(unique(tmp_data$pathology.group) %in% c(\"early\",\"no\"))==2){\n",
    "#       robustness_early = .sconline.RobustFC(inputData=tmp_data, \n",
    "#                                             batch_col=subject_id, \n",
    "#                                             contrast_col=\"pathology.group\", \n",
    "#                                             contrast_1=\"early\", \n",
    "#                                             contrast_2=\"no\", \n",
    "#                                             sex_col=NULL,\n",
    "#                                             ncores=5,\n",
    "#                                             groupLevel=F)\n",
    "\n",
    "#       robustness_early=do.call(\"rbind\",robustness_early)\n",
    "#       robustness_cell.count.1=aggregate(cell.count.1~gene,data=robustness_early,mean)\n",
    "#       robustness_FCscore=aggregate(score_logFC~gene,data=robustness_early,mean)\n",
    "#       robustness_PCTscore=aggregate(score_pct~gene,data=robustness_early,mean)\n",
    "#       robustness_meanRefCount=aggregate(ref_count~gene,data=robustness_early,mean)\n",
    "#       robustness_early=merge(robustness_FCscore,robustness_PCTscore,by=\"gene\")\n",
    "#       robustness_early=merge(robustness_early,robustness_meanRefCount,by=\"gene\")\n",
    "#       robustness_early=merge(robustness_early,robustness_cell.count.1,by=\"gene\")\n",
    "#       robustness_early=robustness_early[order(robustness_early$score_pct,decreasing = T),]\n",
    "#       robustness_early$pathology.group=\"early\"\n",
    "      \n",
    "#       tmp_res_seurat=.myEvalMarkers(object=tmp_data_seurat, \n",
    "#                                     cells.1=colnames(tmp_data_seurat)[which(tmp_data_seurat@meta.data$pathology.group==\"early\")],\n",
    "#                                     cells.2=colnames(tmp_data_seurat)[which(tmp_data_seurat@meta.data$pathology.group==\"no\")], \n",
    "#                                     slot = \"data\", \n",
    "#                                     features = NULL, \n",
    "#                                     thresh.min = 0, \n",
    "#                                     pseudocount.use = 1,\n",
    "#                                     cells.1.weight.col=NULL,\n",
    "#                                     cluster_name=iclust)\n",
    "\n",
    "#       colnames(tmp_res_seurat)=paste0(\"seurat_\",colnames(tmp_res_seurat))\n",
    "#       tmp_res_seurat$gene=row.names(tmp_res_seurat)\n",
    "#       robustness_early=merge(robustness_early,tmp_res_seurat,by=\"gene\",all.x=T)\n",
    "#       res_robustness=c(res_robustness,list(robustness_early))\n",
    "      \n",
    "#     }\n",
    "    \n",
    "#     if(sum(unique(tmp_data$pathology.group) %in% c(\"late\",\"no\"))==2){\n",
    "#       robustness_late=.sconline.RobustFC(inputData=tmp_data,\n",
    "#                                           batch_col=subject_id,\n",
    "#                                           contrast_col=\"pathology.group\",\n",
    "#                                           contrast_1=\"late\",\n",
    "#                                           contrast_2=\"no\",\n",
    "#                                           sex_col=NULL,\n",
    "#                                           ncores=5,\n",
    "#                                           groupLevel=F)\n",
    "\n",
    "#       robustness_late=do.call(\"rbind\",robustness_late)\n",
    "#       robustness_cell.count.1=aggregate(cell.count.1~gene,data=robustness_late,mean)\n",
    "#       robustness_FCscore=aggregate(score_logFC~gene,data=robustness_late,mean)\n",
    "#       robustness_PCTscore=aggregate(score_pct~gene,data=robustness_late,mean)\n",
    "#       robustness_meanRefCount=aggregate(ref_count~gene,data=robustness_late,mean)\n",
    "#       robustness_late=merge(robustness_FCscore,robustness_PCTscore,by=\"gene\")\n",
    "#       robustness_late=merge(robustness_late,robustness_meanRefCount,by=\"gene\")\n",
    "#       robustness_late=merge(robustness_late,robustness_cell.count.1,by=\"gene\")\n",
    "#       robustness_late=robustness_late[order(robustness_late$score_pct,decreasing = T),]\n",
    "      \n",
    "#       robustness_late$pathology.group=\"late\"\n",
    "      \n",
    "#       tmp_res_seurat=.myEvalMarkers(object=tmp_data_seurat, \n",
    "#                                     cells.1=colnames(tmp_data_seurat)[which(tmp_data_seurat@meta.data$status==\"late\")],\n",
    "#                                     cells.2=colnames(tmp_data_seurat)[which(tmp_data_seurat@meta.data$status==\"no\")], \n",
    "#                                     slot = \"data\", \n",
    "#                                     features = NULL,\n",
    "#                                     thresh.min = 0, \n",
    "#                                     pseudocount.use = 1,\n",
    "#                                     cells.1.weight.col=NULL,\n",
    "#                                     cluster_name=iclust)\n",
    "#       colnames(tmp_res_seurat)=paste0(\"seurat_\",colnames(tmp_res_seurat))\n",
    "#       tmp_res_seurat$gene=row.names(tmp_res_seurat)\n",
    "#       robustness_late=merge(robustness_late,tmp_res_seurat,by=\"gene\",all.x=T)\n",
    "#       res_robustness=c(res_robustness,list(robustness_late))\n",
    "#     }\n",
    "    \n",
    "#   }\n",
    "\n",
    "#   # Rename the columns of the results based on the status\n",
    "#   res_robustness <- lapply(res_robustness,function(x){\n",
    "#     if(unique(x$pathology.group) == \"early\"){\n",
    "#       colnames(x) <- paste0(\"early.\",colnames(x))\n",
    "#     }\n",
    "#     else if(unique(x$pathology.group) == \"late\"){\n",
    "#       colnames(x) <- paste0(\"late.\",colnames(x))\n",
    "#     }\n",
    "    \n",
    "#     return(x)\n",
    "#   })\n",
    "  \n",
    "#   res_robustness.early <- res_robustness[c(TRUE,FALSE)]\n",
    "#   res_robustness.late <- res_robustness[c(FALSE,TRUE)]\n",
    "  \n",
    "  \n",
    "#   names(res_robustness.early) <- lapply(res_robustness.early, function(x){\n",
    "#     unique(x$early.cell_type)\n",
    "#   })\n",
    "  \n",
    "#   names(res_robustness.late) <- lapply(res_robustness.late, function(x){\n",
    "#     unique(x$late.cell_type)\n",
    "#   })\n",
    "  \n",
    "#   res.rob <- lapply(names(res_robustness.late),function(x){\n",
    "#     print(x)\n",
    "#     out <- merge(res_robustness.early[[x]], \n",
    "#                 res_robustness.late[[x]], \n",
    "#                 by.x=\"early.gene\", \n",
    "#                 by.y=\"late.gene\",\n",
    "#                 all=TRUE)\n",
    "\n",
    "#     return(out)\n",
    "#   })\n",
    "  \n",
    "#   print(\"Robustness merged by cell type\")\n",
    "  \n",
    "#   names(res.rob) <- lapply(res.rob, function(x){\n",
    "#     unique(x$KO.cell_type)\n",
    "#   })\n",
    "#   return(res.rob)\n",
    "# }\n",
    "\n",
    "# rob.res=.robustness_scoresfn(input_exp_data=adata_annot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af78c0b",
   "metadata": {},
   "source": [
    "### **Jack Kniffing**\n",
    "\n",
    "Jack-knifing is a resampling technique in which we repeat the analysis on a subset of samples to assess the robustness of the observed patterns. If results are driven by outlier samples, we expect to see a bimodal or multi-modal pattern when we jack-knife the analysis. `This technique is most usefull when we are dealing with large datasets with +10 controls and +10 experiment conditions.`\n",
    "\n",
    "We can perform jack-knife analysis at two levels:\n",
    "\n",
    "- `Leave-one-out-validation (LOOV)`: In this type of analysis, we iteratively exclude one subject/donor from the analysis and examine the p-value distribution of the genes.\n",
    "\n",
    "- `50% resampling:` In this analysis, iterating 100 times, we randomly select 50% of donors from the cohort and repeat the analysis to see if the logFC pattern of genes remain the same or change. The number of iterations that the logFC remain same as the full cohort provide a measure of robustness on the patterns\n",
    "\n",
    "Below we perform jack-knifing to assess the robustness of the DE patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e61b5a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "myJK_DEfn=function(inputExpData,dc,bkg_genes,de_method,norm_method,rand_var,covList,quantile_norm=T){\n",
    "    res_arranged=NULL\n",
    "\n",
    "    #requiring existence of at least 6 pseudocells for the DE analysis\n",
    "    if(length(unique(inputExpData$pathology.group))>1&ncol(inputExpData)>5){\n",
    "      \n",
    "        #inputExpData=x;covariates=covList;randomEffect=rand_effect;bkg_genes=tmp_bkg_genes;quantile.norm=quantile_norm;prior.count=1\n",
    "        res = .sconline.fitLimmaFn(inputExpData=inputExpData,\n",
    "                                covariates=covList,\n",
    "                                randomEffect = rand_var,\n",
    "                                bkg_genes = bkg_genes,\n",
    "                                quantile.norm = quantile_norm,\n",
    "                                prior.count = 1,\n",
    "                                DEmethod = de_method,\n",
    "                                normalization = norm_method)\n",
    "        #check the dc object, the usual consensus.correlation that I get is in the range of ~0.2 or above if rand=T\n",
    "        \n",
    "        if(sum(grepl(\"pathology.group\", colnames(res$model)))>0){\n",
    "            #Defining the comparisosn that we are interested in to know it's logFC and pval\n",
    "            # Now, use this in makeContrasts\n",
    "            contr <- makeContrasts(\n",
    "                pathology.groupearly - pathology.groupno,\n",
    "                pathology.grouplate - pathology.groupno,\n",
    "                pathology.grouplate - pathology.groupearly,\n",
    "                (pathology.groupearly + pathology.grouplate)/2 - pathology.groupno,\n",
    "                levels = res$model\n",
    "                )\n",
    "            \n",
    "            fit2=contrasts.fit(res$fit, contrasts=contr)\n",
    "            #Explore setting robust=F\n",
    "            fit2=eBayes(fit2,robust = T,trend=T)\n",
    "            #running topTable for each contrast\n",
    "            res_early=topTable(fit2,number=dim(fit2)[1], adjust.method = \"BH\", coef=\"pathology.groupearly - pathology.groupno\");\n",
    "            res_late=topTable(fit2,number=dim(fit2)[1], adjust.method = \"BH\", coef=\"pathology.grouplate - pathology.groupno\");\n",
    "            res_lve=topTable(fit2,number=dim(fit2)[1], adjust.method = \"BH\", coef=\"pathology.grouplate - pathology.groupearly\");\n",
    "            res_ad=topTable(fit2,number=dim(fit2)[1], adjust.method = \"BH\", coef=\"(pathology.groupearly + pathology.grouplate)/2 - pathology.groupno\");\n",
    "            \n",
    "            res_early$gene=row.names(res_early)\n",
    "            res_late$gene=row.names(res_early)\n",
    "            res_ad$gene=row.names(res_ad)\n",
    "            res_lve$gene=row.names(res_lve)\n",
    "\n",
    "            colnames(res_early)=paste0(\"early.\",colnames(res_early))\n",
    "            colnames(res_late)=paste0(\"late.\",colnames(res_late))\n",
    "            colnames(res_ad)=paste0(\"ad.\",colnames(res_ad))\n",
    "            colnames(res_lve)=paste0(\"lve.\",colnames(res_lve))\n",
    "\n",
    "            # Merge res_early and res_late\n",
    "            merged_early_late <- merge(res_early, res_late, by.x=\"early.gene\", by.y=\"late.gene\", all=TRUE)\n",
    "            merged_lve <- merge(merged_early_late, res_lve, by.x=\"early.gene\", by.y=\"lve.gene\", all=TRUE)\n",
    "            merged_all <- merge(merged_lve, res_ad, by.x=\"early.gene\", by.y=\"ad.gene\", all=TRUE)\n",
    "            \n",
    "            res_arranged <- merged_all\n",
    "\n",
    "            res_arranged$blocked_analysis=res$blocked_analysis\n",
    "            res_arranged$block.cor=res$dc$consensus.correlation #check the dc object, the usual consensus.correlation range is ~0.2 or above if rand=T\n",
    "            res_arranged$cell_type=unique(as.character(x$cell_type))\n",
    "            colnames(res_arranged)[colnames(res_arranged)==\"early.gene\"]=\"gene\"\n",
    "      }\n",
    "    }\n",
    "    return(res_arranged)\n",
    "}\n",
    "\n",
    "myJKloov_arrangeFn=function(inputList){\n",
    "    pval_colname=colnames(inputList[[1]])[grepl(\"P\\\\.Value\",colnames(inputList[[1]]))]\n",
    "    logFC_colname=colnames(inputList[[1]])[grepl(\"logFC\",colnames(inputList[[1]]))]\n",
    "    for(i in 1:length(inputList)){\n",
    "        inputList[[i]]$zscore=qnorm(inputList[[i]][,pval_colname]/2,lower.tail=F)*sign(inputList[[i]][,logFC_colname])\n",
    "    }\n",
    "    \n",
    "    \n",
    "    res=inputList[[1]][,c(\"gene\",\"zscore\")]\n",
    "    for(i in 2:length(inputList)){\n",
    "        res=suppressWarnings(merge(res,inputList[[i]][,c(\"gene\",\"zscore\")],by=\"gene\"))\n",
    "    }\n",
    "    \n",
    "    res_max_pval=apply(res[,-1],1,function(x) {\n",
    "        y=table(sign(x))\n",
    "        y=y[order(as.numeric(y),decreasing=T)]\n",
    "        y=names(y)[1]\n",
    "        x=pnorm(abs(x),lower.tail = F)*2\n",
    "        x[sign(x)!=y]=1\n",
    "        return(max(x))\n",
    "    })\n",
    "    res_max_pval=data.frame(gene=res[,1],max_pval=as.numeric(res_max_pval),stringsAsFactors = F)\n",
    "    return(res_max_pval)\n",
    "}\n",
    "\n",
    "\n",
    "myJK50pct_arrangeFn=function(inputList){\n",
    "    logFC_colname=colnames(inputList[[1]])[grepl(\"logFC\",colnames(inputList[[1]]))]\n",
    "    \n",
    "    res=inputList[[1]][,c(\"gene\",logFC_colname)]\n",
    "    for(i in 2:length(inputList)){\n",
    "        res=suppressWarnings(merge(res,inputList[[i]][,c(\"gene\",logFC_colname)],by=\"gene\"))\n",
    "    }\n",
    "    \n",
    "    res_concordance_score=lapply(1:nrow(res),function(i) {\n",
    "        x=as.numeric(res[i,-1])\n",
    "        y=table(sign(x))/length(x)\n",
    "        y=y[order(as.numeric(y),decreasing=T)]\n",
    "        \n",
    "        return(data.frame(gene=res[i,1],pattern=names(y)[1],score=y[1],jk_count=length(x),stringsAsFactors = F))\n",
    "    })\n",
    "    res_concordance_score=do.call(\"rbind\",res_concordance_score)\n",
    "    return(res_concordance_score)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4eeade",
   "metadata": {},
   "source": [
    "#### **Leave-One-Out-Validation** \n",
    "\n",
    "The default DE analysis method can be time consuming, and hence making it impractical to apply iteratively. \n",
    "\n",
    "To remedy this, we make use of argument in the function. Providing the object substantially increases the performance by avoiding the calculation of the mixed-linear model parameters. Note that in general we need to re-calculate for each cohort and cell type individually. However, we can make the approximation that does not change substantially between the full cohort and the iterations in LOOV analysis since we are only excluding only one subject and our dataset is large. We only need values of from the and we have saved these values as in our DE analysis step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eb5be238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Number of unique subjects <= 10 or `jack_knifing` param set to `FALSE`....\"\n",
      "[1] \"Warning.....\"\n",
      "[1] \"Skipping Jack Knifing\"\n"
     ]
    }
   ],
   "source": [
    "%%R -i jack_knifing -o res_w_jk -o DE_results\n",
    "\n",
    "\n",
    "########### Setting the parameters ################\n",
    "\n",
    "\n",
    "if (filter_genes){\n",
    "    bkg_gene_pct_thr = gene_celltype_threshold # selecting genes that are expressed in > 10% of cells\n",
    "    bkg_gene_count_thr = 10\n",
    "} else{\n",
    "    bkg_gene_pct_thr = NULL\n",
    "}\n",
    "\n",
    "if (jack_knifing){\n",
    "\n",
    "    res_w_jk <- list()\n",
    "\n",
    "    for (strategy in pseudobulking_strategies){\n",
    "\n",
    "        res_w_jk[[strategy]] <- list()\n",
    "\n",
    "        for (de_method in deg_methods_to_run){\n",
    "\n",
    "            res_w_jk[[strategy]][[de_method]] <- list()\n",
    "\n",
    "            for (norm_method in normalization_methods){\n",
    "                names(DE_results[[strategy]][[de_method]][[norm_method]])=unlist(lapply(DE_results[[strategy]][[de_method]][[norm_method]],\n",
    "                                                                function(x) unique(x$cell_type)))\n",
    "\n",
    "                for(iclust in names(pseudobulk_strategy_list[[strategy]])){\n",
    "                    tmp_data=pseudobulk_strategy_list[[strategy]][[iclust]]\n",
    "                    if(!is.null(bkg_gene_pct_thr)){\n",
    "                        #background genes should be selectd based on the cell level expression data\n",
    "                        tmp_bkg_genes = counts(adata_annot)[,which(adata_annot$cell_type==iclust)]\n",
    "                        tmp_bkg_genes_counts=rowSums(tmp_bkg_genes>0)\n",
    "                        tmp_bkg_genes_frac=tmp_bkg_genes_counts/sum(adata_annot$cell_type==iclust)\n",
    "                        tmp_bkg_genes=row.names(adata_annot)[tmp_bkg_genes_frac>=bkg_gene_pct_thr&tmp_bkg_genes_counts>=bkg_gene_count_thr]\n",
    "                        \n",
    "                    } else {\n",
    "                        tmp_bkg_genes=NULL\n",
    "                    }\n",
    "\n",
    "                    tmp_dc.object=list(consensus.correlation=unique(DE_results[[strategy]][[de_method]][[norm_method]]$block.cor))\n",
    "                    res_list_early=list()\n",
    "                    res_list_late=list()\n",
    "                    res_list_ad=list()\n",
    "                    res_list_lve=list()\n",
    "\n",
    "                    \n",
    "                    for(isbj in unique(tmp_data[[subject_id]])){\n",
    "                        \n",
    "                        \n",
    "                        tmp_res = myJK_DEfn(inputExpData=tmp_data[, which(tmp_data[[subject_id]] != isbj)],\n",
    "                                            dc=tmp_dc.object,\n",
    "                                            bkg_genes=tmp_bkg_genes,\n",
    "                                            de_method=de_method,\n",
    "                                            norm_method=norm_method,\n",
    "                                            quantile_norm=T,\n",
    "                                            rand_var=subject_id,\n",
    "                                            covList=covList)\n",
    "                            \n",
    "                                            \n",
    "                        if(isbj %in% unique(tmp_data[[subject_id]][tmp_data$pathology.group %in% c(\"no\", \"early\")])){\n",
    "                            res_list_early = c(res_list_early, list(tmp_res[, c(\"gene\", \"early.logFC\", \"early.P.Value\")]))\n",
    "                        }\n",
    "                        if(isbj %in% unique(tmp_data[[subject_id]][tmp_data$pathology.group %in% c(\"no\", \"late\")])){\n",
    "                            res_list_late = c(res_list_late, list(tmp_res[, c(\"gene\", \"late.logFC\", \"late.P.Value\")]))\n",
    "                        }\n",
    "                        if(isbj %in% unique(tmp_data[[subject_id]][tmp_data$pathology.group %in% c(\"no\", \"late\", \"early\")])){\n",
    "                            res_list_ad = c(res_list_ad, list(tmp_res[, c(\"gene\", \"ad.logFC\", \"ad.P.Value\")]))\n",
    "                        }\n",
    "                        if(isbj %in% unique(tmp_data[[subject_id]][tmp_data$pathology.group %in% c(\"late\", \"early\")])){\n",
    "                            res_list_lve = c(res_list_lve, list(tmp_res[, c(\"gene\", \"lvd.logFC\", \"lve.P.Value\")]))\n",
    "                        } \n",
    "                    }\n",
    "\n",
    "                    res_jk_early=myJKloov_arrangeFn(inputList=res_list_early)\n",
    "                    colnames(res_jk_early)[2]=paste0(\"jk_early.\",colnames(res_jk_early)[2])\n",
    "                    \n",
    "                    res_jk_late=myJKloov_arrangeFn(inputList=res_list_late)\n",
    "                    colnames(res_jk_late)[2]=paste0(\"jk_late.\",colnames(res_jk_late)[2])\n",
    "                    \n",
    "                    res_jk_ad=myJKloov_arrangeFn(inputList=res_list_ad)\n",
    "                    colnames(res_jk_ad)[2]=paste0(\"jk_ad.\",colnames(res_jk_ad)[2])\n",
    "\n",
    "                    res_jk_lve=myJKloov_arrangeFn(inputList=res_list_lve)\n",
    "                    colnames(res_jk_lve)[2]=paste0(\"jk_lve.\",colnames(res_jk_lve)[2])\n",
    "\n",
    "                    res_jk=merge(res_jk_early, res_jk_late, by=\"gene\")\n",
    "                    res_jk=merge(res_jk, res_jk_ad, by='gene')\n",
    "                    res_jk=merge(res_jk, res_lve, by='gene')\n",
    "                    \n",
    "                    res_jk$jk_early_partial_fdr=p.adjust(res_jk$k_early.max_pval[res_jk$early.adj.P.Val<0.1],method=\"BH\")\n",
    "                    res_jk$jk_late_partial_fdr=p.adjust(res_jk$k_late.max_pval[res_jk$late.adj.P.Val<0.1],method=\"BH\")\n",
    "                    res_jk$jk_ad_partial_fdr=p.adjust(res_jk$k_ad.max_pval[res_jk$ad.adj.P.Val<0.1],method=\"BH\")\n",
    "                    res_jk$jk_lve_partial_fdr=p.adjust(res_jk$k_lve.max_pval[res_jk$lve.adj.P.Val<0.1],method=\"BH\")\n",
    "\n",
    "                    res_w_jk[[strategy]][[de_method]][[norm_method]]=c(res_w_jk,list(merge(DE_results[['random']][[de_method]][[norm_method]][[iclust]],\n",
    "                                                        res_jk,by=\"gene\")))\n",
    "                                                        \n",
    "                    rm(res_jk,res_jk_early,res_jk_late,res_jk_ad,res_jk_lve,\n",
    "                    tmp_bkg_genes,res_list_early,res_list_late,res_list_ad,res_list_lve)\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "} else {\n",
    "    print('Number of unique subjects <= 10 or `jack_knifing` param set to `FALSE`....')\n",
    "    print('Warning.....')\n",
    "    print('Skipping Jack Knifing')\n",
    "    res_w_jk <- NULL\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6bf927c1",
   "metadata": {},
   "source": [
    "##### **Save Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c60769d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_name in test_names:\n",
    "    fig_dir = f'../results/{test_name}/{save_prefix}/DEG/'\n",
    "\n",
    "    if not os.path.exists(fig_dir):\n",
    "        os.makedirs(fig_dir)\n",
    "\n",
    "    for strategy in pseudobulking_strategies:\n",
    "        for de_method in deg_methods_to_run:\n",
    "            for norm_method in normalization_methods:\n",
    "                \n",
    "                file_path = fig_dir + f'Limma_{de_method.capitalize()}_{strategy}_degs.xlsx'\n",
    "                \n",
    "                for cell_type in celltypes:\n",
    "\n",
    "                    if test_name!='late_vs_early':\n",
    "                        df = DE_results[strategy][de_method][norm_method][cell_type].loc[:,DE_results[strategy][de_method][norm_method][cell_type].columns.str.startswith(test_name.split('_vs_')[0])].copy()\n",
    "                        df.columns = df.columns.str.replace(f'{test_name.split(\"_vs_\")[0]}.', \"\")\n",
    "                    elif test_name=='late_vs_early':\n",
    "                        df = DE_results[strategy][de_method][norm_method][cell_type].loc[:,DE_results[strategy][de_method][norm_method][cell_type].columns.str.startswith('lve')].copy()\n",
    "                        df.columns = df.columns.str.replace(f'lve.', \"\")\n",
    "\n",
    "                    df['gene'] = DE_results[strategy][de_method][norm_method][cell_type]['gene'].copy()\n",
    "                    df['cell_type'] = DE_results[strategy][de_method][norm_method][cell_type]['cell_type'].copy()\n",
    "                    df['blocked_analysis'] = DE_results[strategy][de_method][norm_method][cell_type]['blocked_analysis'].copy()\n",
    "                    if 'block.cor' in DE_results[strategy][de_method][norm_method][cell_type].columns:\n",
    "                        df['block.cor'] = DE_results[strategy][de_method][norm_method][cell_type]['block.cor'].copy()\n",
    "                    else:\n",
    "                        df['block.cor'] = 'NA'\n",
    "                    df['de_family'] = f'{strategy}_pseudobulk_strategy'\n",
    "                    df['de_method'] = 'Limma'\n",
    "                    df['de_type'] = de_method                  \n",
    "                    df = df.rename(columns={'logFC': 'avg_logFC', 'P.Value': 'p_val', 'adj.P.Val': 'p_val_adj'})\n",
    "                    df['abs_logFC'] = abs(df['avg_logFC'])   \n",
    "                    df['direction'] = df['avg_logFC'].apply(lambda x: \"up\" if x>0 else \"down\") \n",
    "\n",
    "                    df = df[['cell_type', 'gene', 'avg_logFC', 'p_val', 'p_val_adj', 'de_family',\n",
    "                                'de_method', 'de_type', 'abs_logFC', 'direction', 'blocked_analysis',\n",
    "                                'block.cor']]\n",
    "                    \n",
    "                    if os.path.exists(file_path):\n",
    "                        with pd.ExcelWriter(file_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "                            book = writer.book\n",
    "                            if cell_type in book.sheetnames:\n",
    "                                print(f\"Sheet {cell_type} already exists in {file_path}, data will be overwritten!\")\n",
    "                            df.to_excel(writer, sheet_name=cell_type, na_rep='NA')\n",
    "                    else:\n",
    "                        with pd.ExcelWriter(file_path, engine='openpyxl') as writer:\n",
    "                            df.to_excel(writer, sheet_name=cell_type, na_rep='NA')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6f8a7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scRNA_seq_meta_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "2f414a000012e1980f5fd1119ed6b9bf8cc73b51e37b52eb52a16ff857effd1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
